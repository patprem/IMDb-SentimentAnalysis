{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJw1MnnZIabjub3N3OsA+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patprem/SentimentAnalysis/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdrSSyzdTq70"
      },
      "source": [
        "**Sentiment Analysis of IMDb Movie Reviews**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lyq87CUT_e5"
      },
      "source": [
        "Importing the basic and required libraries used in this project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVnF5UkYY1hH"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_v6-skIURPp"
      },
      "source": [
        "Mounting personal Google Drive to load the dataset. **IMPORTANT: Change the directory and root path variable accordingly to yours.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nZTy4aXY8W8",
        "outputId": "878ce8a9-197e-4915-9370-f883abbfb2ab"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "#Mount your Google drive to the VM\n",
        "drive.mount('/content/gdrive')\n",
        "sys.path.append(\"/content/gdrive/My Drive/ECE4179 S1 2021 Prathik\")\n",
        "\n",
        "#set a root path variable to use\n",
        "ROOT = \"/content/gdrive/My Drive/ECE4179 S1 2021 Prathik/Final Project\"\n",
        "\n",
        "#Follow link and give permission, copy code and paste in text box\n",
        "#You only have to do this once per session"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZM2bUiUh05"
      },
      "source": [
        "Reading the data from the loaded dataset\n",
        "\n",
        "**IMPORTANT:** \n",
        "1. Download the dataset provided under Datasets section on README.md or download from this links: [IMDB Dataset (csv)](https://www.kaggle.com/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews/data) and [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
        "2. Import the downloaded datasets onto your local Google Drive and **change the path variable** accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D33K59RZY_hw"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "#import io\n",
        "#dataset = pd.read_csv(io.BytesIO(uploaded['IMDB Dataset.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "# Reading the data from the dataset.\n",
        "dataset = pd.read_csv('gdrive/My Drive/ECE4179 S1 2021 Prathik/Final Project/IMDB Dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If you have successfully executed all cells upto this point, then just simply click *Run all* under Runtime tab or press *Ctrl+F9* to execute the remanining cells or follow through the comments besides each cell below to get an understanding of the methodology of this project."
      ],
      "metadata": {
        "id": "gCp5U69k3HTX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YqsMQY7Vs-x"
      },
      "source": [
        "Exploring the loaded dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "id": "4SGHZnMOZHOy",
        "outputId": "81dc7559-915c-4273-81d4-d08ae3ff38c8"
      },
      "source": [
        "pd.set_option('display.max_colwidth',2000) # set the column width to 2000 so that we can read the complete review.\n",
        "pd.set_option('max_rows', 200) \n",
        "dataset.head(10) # setting .head(10) to read just the first 10 reviews from the dataset."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.&lt;br /&gt;&lt;br /&gt;The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.&lt;br /&gt;&lt;br /&gt;We wish Mr. Mattei good luck and await anxiously for his next work.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in me.I grew up on black and white TV and Seahunt with Gunsmoke were my hero's every week.You have my vote for a comeback of a new sea hunt.We need a change of pace in TV and this would work for a world of under water adventure.Oh by the way thank you for an outlet like this to view many viewpoints about TV and the many movies.So any ole way I believe I've got what I wanna say.Would be nice to read some more plus points about sea hunt.If my rhymes would be 10 lines would you let me submit,or leave me out to be in doubt and have me to quit,If this is so then I must go so lets do it.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.&lt;br /&gt;&lt;br /&gt;It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this film on here I was looking forward to watching this film. Bad mistake. I've seen 950+ films and this is truly one of the worst of them - it's awful in almost every way: editing, pacing, storyline, 'acting,' soundtrack (the film's only song - a lame country tune - is played no less than four times). The film looks cheap and nasty and is boring in the extreme. Rarely have I been so happy to see the end credits of a film. &lt;br /&gt;&lt;br /&gt;The only thing that prevents me giving this a 1-score is Harvey Keitel - while this is far from his best performance he at least seems to be making a bit of an effort. One for Keitel obsessives only.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.&lt;br /&gt;&lt;br /&gt;Great Camp!!!</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.  positive\n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.  positive\n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.  positive\n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.  negative\n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                              Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.  positive\n",
              "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.  positive\n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in me.I grew up on black and white TV and Seahunt with Gunsmoke were my hero's every week.You have my vote for a comeback of a new sea hunt.We need a change of pace in TV and this would work for a world of under water adventure.Oh by the way thank you for an outlet like this to view many viewpoints about TV and the many movies.So any ole way I believe I've got what I wanna say.Would be nice to read some more plus points about sea hunt.If my rhymes would be 10 lines would you let me submit,or leave me out to be in doubt and have me to quit,If this is so then I must go so lets do it.  positive\n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.  negative\n",
              "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Encouraged by the positive comments about this film on here I was looking forward to watching this film. Bad mistake. I've seen 950+ films and this is truly one of the worst of them - it's awful in almost every way: editing, pacing, storyline, 'acting,' soundtrack (the film's only song - a lame country tune - is played no less than four times). The film looks cheap and nasty and is boring in the extreme. Rarely have I been so happy to see the end credits of a film. <br /><br />The only thing that prevents me giving this a 1-score is Harvey Keitel - while this is far from his best performance he at least seems to be making a bit of an effort. One for Keitel obsessives only.  negative\n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bncfjF5mZIiD",
        "outputId": "cfb735cf-4623-4b9a-a948-9d79421083a7"
      },
      "source": [
        "dataset.info() # information about the dataset; two columns: review and sentiment,\n",
        "# where sentiment is the target column or the column that we need to predict.\n",
        "\n",
        "# number of positive and negative reviews in the dataset.\n",
        "# dataset is completely balanced and has equal number of positive and negative\n",
        "# sentiments.\n",
        "dataset['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    25000\n",
              "positive    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "Xp_HzLoAZLqY",
        "outputId": "41565ca2-b5b4-484e-83bd-fea4fe8763d5"
      },
      "source": [
        "# reading second review from the dataset and checking how the contents of the review is\n",
        "# and why we need to use NLP (Natural Language Processing) tasks on this dataset.\n",
        "review = dataset['review'].loc[10]\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.<br /><br />At first it was very odd and pretty funny but as the movie progressed I didn\\'t find the jokes or oddness funny anymore.<br /><br />Its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually I just lost interest.<br /><br />I imagine this film would appeal to a stoner who is currently partaking.<br /><br />For something similar but better try \"Brother from another planet\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBf5XHC3WEiW"
      },
      "source": [
        "From the above review (output), we can see that there HTML contents, punctuations, special characters, stopwords and others which do not offer much insight into the prediction of our model. The following NLP tasks (text cleaning technqiues) are implemented.\n",
        "\n",
        "1.   Eliminating HTML tags/contents like 'br\"\n",
        "2.   Removing punctuations and special characters like |, /, apostrophes, commas and other punctuation marks and etc.\n",
        "3.   Remove stopwords that do not affect the prediction of our outcome and does not offer much insight such as 'are', 'is', 'the' and etc.\n",
        "4.   Use Lemmatization to bring back multiple forms of the same word to their common/base root. For example, words like 'ran', 'running', 'runs' to 'run'.\n",
        "5.   Using Text Tokenization and Vectorization to encode numerical values to our data after the above text cleaning techniques.\n",
        "6.   Lastly, fit these data to a deep learning model like Convolutional Neural Network (CNN) and LinearSVC model and compare the discrepancies between them\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8QLOdpuYZNJC",
        "outputId": "a356f26c-6fef-4e79-e579-a144eeba09ab"
      },
      "source": [
        "# Removing HTML contents like \"<br>\"\n",
        "# BeautifulSoup is a Python library for extracting data out of HTML and XML files,\n",
        "# by omitting HTML contents such as \"<br>\"\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(review, \"html.parser\")\n",
        "review = soup.get_text()\n",
        "review\n",
        "# notice that the HTML tags are eliminated."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.At first it was very odd and pretty funny but as the movie progressed I didn\\'t find the jokes or oddness funny anymore.Its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually I just lost interest.I imagine this film would appeal to a stoner who is currently partaking.For something similar but better try \"Brother from another planet\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "wqtYlrXDZTIv",
        "outputId": "9117d4c0-9a81-42e7-aec2-9ad507dd47d6"
      },
      "source": [
        "# Removal of other special characters or punctuations except upper or lower case \n",
        "# letters using Regular Expressions (Regex)\n",
        "import re # importing Regex\n",
        "review = re.sub('\\[[^]]*\\]', ' ', review) # removing punctuations\n",
        "review = re.sub('[^a-zA-Z]', ' ', review) # regex; removing strings that contains a non-letter \n",
        "# i.e., remove except a-z to A-Z\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines At first it was very odd and pretty funny but as the movie progressed I didn t find the jokes or oddness funny anymore Its a low budget film  thats never a problem in itself   there were some pretty interesting characters  but eventually I just lost interest I imagine this film would appeal to a stoner who is currently partaking For something similar but better try  Brother from another planet '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "QL7E5X_fZUIj",
        "outputId": "0fcc33c5-6bff-40f2-e600-edc87f329cfd"
      },
      "source": [
        "# set all characters to lower case for simplicity\n",
        "review = review.lower()\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'phil the alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines at first it was very odd and pretty funny but as the movie progressed i didn t find the jokes or oddness funny anymore its a low budget film  thats never a problem in itself   there were some pretty interesting characters  but eventually i just lost interest i imagine this film would appeal to a stoner who is currently partaking for something similar but better try  brother from another planet '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qVBsnzAZNzC"
      },
      "source": [
        "Tokenization of reviews in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6YH1KHWZYac",
        "outputId": "357b20af-c5d1-4bc2-87dd-92167a933271"
      },
      "source": [
        "# Tokenization of reviews\n",
        "# Stopwords removal: Split the text into tokens since stopwords removal \n",
        "# works on every word in the text.\n",
        "review = review.split()\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['phil',\n",
              " 'the',\n",
              " 'alien',\n",
              " 'is',\n",
              " 'one',\n",
              " 'of',\n",
              " 'those',\n",
              " 'quirky',\n",
              " 'films',\n",
              " 'where',\n",
              " 'the',\n",
              " 'humour',\n",
              " 'is',\n",
              " 'based',\n",
              " 'around',\n",
              " 'the',\n",
              " 'oddness',\n",
              " 'of',\n",
              " 'everything',\n",
              " 'rather',\n",
              " 'than',\n",
              " 'actual',\n",
              " 'punchlines',\n",
              " 'at',\n",
              " 'first',\n",
              " 'it',\n",
              " 'was',\n",
              " 'very',\n",
              " 'odd',\n",
              " 'and',\n",
              " 'pretty',\n",
              " 'funny',\n",
              " 'but',\n",
              " 'as',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'progressed',\n",
              " 'i',\n",
              " 'didn',\n",
              " 't',\n",
              " 'find',\n",
              " 'the',\n",
              " 'jokes',\n",
              " 'or',\n",
              " 'oddness',\n",
              " 'funny',\n",
              " 'anymore',\n",
              " 'its',\n",
              " 'a',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'film',\n",
              " 'thats',\n",
              " 'never',\n",
              " 'a',\n",
              " 'problem',\n",
              " 'in',\n",
              " 'itself',\n",
              " 'there',\n",
              " 'were',\n",
              " 'some',\n",
              " 'pretty',\n",
              " 'interesting',\n",
              " 'characters',\n",
              " 'but',\n",
              " 'eventually',\n",
              " 'i',\n",
              " 'just',\n",
              " 'lost',\n",
              " 'interest',\n",
              " 'i',\n",
              " 'imagine',\n",
              " 'this',\n",
              " 'film',\n",
              " 'would',\n",
              " 'appeal',\n",
              " 'to',\n",
              " 'a',\n",
              " 'stoner',\n",
              " 'who',\n",
              " 'is',\n",
              " 'currently',\n",
              " 'partaking',\n",
              " 'for',\n",
              " 'something',\n",
              " 'similar',\n",
              " 'but',\n",
              " 'better',\n",
              " 'try',\n",
              " 'brother',\n",
              " 'from',\n",
              " 'another',\n",
              " 'planet']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbNRqbyycHtg"
      },
      "source": [
        "Removal of Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCl5zLxLZ4D9",
        "outputId": "441e19f5-6f3b-4d47-df41-7b89b7398ac0"
      },
      "source": [
        "# importing nltk library to remove stopwords\n",
        "# Stopwords are words (English language words) that does not add much\n",
        "# meaning to a sentence. Could be safely ignored without sacrificing the \n",
        "# meaning of the sentence or review in this case. Words like 'he', 'have',\n",
        "# 'the' does not provide any insights.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['phil',\n",
              " 'alien',\n",
              " 'one',\n",
              " 'quirky',\n",
              " 'films',\n",
              " 'humour',\n",
              " 'based',\n",
              " 'around',\n",
              " 'oddness',\n",
              " 'everything',\n",
              " 'rather',\n",
              " 'actual',\n",
              " 'punchlines',\n",
              " 'first',\n",
              " 'odd',\n",
              " 'pretty',\n",
              " 'funny',\n",
              " 'movie',\n",
              " 'progressed',\n",
              " 'find',\n",
              " 'jokes',\n",
              " 'oddness',\n",
              " 'funny',\n",
              " 'anymore',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'film',\n",
              " 'thats',\n",
              " 'never',\n",
              " 'problem',\n",
              " 'pretty',\n",
              " 'interesting',\n",
              " 'characters',\n",
              " 'eventually',\n",
              " 'lost',\n",
              " 'interest',\n",
              " 'imagine',\n",
              " 'film',\n",
              " 'would',\n",
              " 'appeal',\n",
              " 'stoner',\n",
              " 'currently',\n",
              " 'partaking',\n",
              " 'something',\n",
              " 'similar',\n",
              " 'better',\n",
              " 'try',\n",
              " 'brother',\n",
              " 'another',\n",
              " 'planet']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FTQqzIHcKTY"
      },
      "source": [
        "\n",
        "**Stemming technique**\n",
        "\n",
        "Stemming is a process to extract the base form of the words by removing affixes from the words.\n",
        "\n",
        "Both Stemming and Lemmatization technqiues are implemented on a sample review here to observe the discrepancies between them and why Lemmatization is a better algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "538-ohzDZ-o4",
        "outputId": "6ef549b6-c90f-484e-8a6d-240c3ac5d46d"
      },
      "source": [
        "# importing PorterStemmer library to perform stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "p_stem = PorterStemmer()\n",
        "review_p_stem = [p_stem.stem(word) for word in review]\n",
        "review_p_stem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['phil',\n",
              " 'alien',\n",
              " 'one',\n",
              " 'quirki',\n",
              " 'film',\n",
              " 'humour',\n",
              " 'base',\n",
              " 'around',\n",
              " 'odd',\n",
              " 'everyth',\n",
              " 'rather',\n",
              " 'actual',\n",
              " 'punchlin',\n",
              " 'first',\n",
              " 'odd',\n",
              " 'pretti',\n",
              " 'funni',\n",
              " 'movi',\n",
              " 'progress',\n",
              " 'find',\n",
              " 'joke',\n",
              " 'odd',\n",
              " 'funni',\n",
              " 'anymor',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'film',\n",
              " 'that',\n",
              " 'never',\n",
              " 'problem',\n",
              " 'pretti',\n",
              " 'interest',\n",
              " 'charact',\n",
              " 'eventu',\n",
              " 'lost',\n",
              " 'interest',\n",
              " 'imagin',\n",
              " 'film',\n",
              " 'would',\n",
              " 'appeal',\n",
              " 'stoner',\n",
              " 'current',\n",
              " 'partak',\n",
              " 'someth',\n",
              " 'similar',\n",
              " 'better',\n",
              " 'tri',\n",
              " 'brother',\n",
              " 'anoth',\n",
              " 'planet']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nQ4mj3-cMh5"
      },
      "source": [
        "**Lemmatization technique**\n",
        "\n",
        "Lemmatization has the same objective as Stemming, however, it takes into consideration the morphological analysis of the words, i.e., it ensures that the root word is a valid English word alphabetically and meaningfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN07YALzaBXQ",
        "outputId": "4bb94258-75b1-4926-d6d8-13a59b7b298d"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemma = WordNetLemmatizer()\n",
        "review = [lemma.lemmatize(word) for word in review]\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['phil',\n",
              " 'alien',\n",
              " 'one',\n",
              " 'quirky',\n",
              " 'film',\n",
              " 'humour',\n",
              " 'based',\n",
              " 'around',\n",
              " 'oddness',\n",
              " 'everything',\n",
              " 'rather',\n",
              " 'actual',\n",
              " 'punchlines',\n",
              " 'first',\n",
              " 'odd',\n",
              " 'pretty',\n",
              " 'funny',\n",
              " 'movie',\n",
              " 'progressed',\n",
              " 'find',\n",
              " 'joke',\n",
              " 'oddness',\n",
              " 'funny',\n",
              " 'anymore',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'film',\n",
              " 'thats',\n",
              " 'never',\n",
              " 'problem',\n",
              " 'pretty',\n",
              " 'interesting',\n",
              " 'character',\n",
              " 'eventually',\n",
              " 'lost',\n",
              " 'interest',\n",
              " 'imagine',\n",
              " 'film',\n",
              " 'would',\n",
              " 'appeal',\n",
              " 'stoner',\n",
              " 'currently',\n",
              " 'partaking',\n",
              " 'something',\n",
              " 'similar',\n",
              " 'better',\n",
              " 'try',\n",
              " 'brother',\n",
              " 'another',\n",
              " 'planet']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_KUP-3teSME"
      },
      "source": [
        "From the above results, we can notice that there is a huge difference between the techniques used. For example, 'little' has become 'littl' after Stemming, whereas it remained as 'little' after Lemmatization. Stemming tries to achieve a reduction in words to their root form but the stem itself is not a valid English word. Hence, Lemmatization is used in this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "lhua7BsifmcR",
        "outputId": "7fdbd240-4e66-4dfd-e1d0-828f95c0e1e3"
      },
      "source": [
        "# merging the words to form a cleaned up version of the text.\n",
        "review = ' '.join(review)\n",
        "review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'phil alien one quirky film humour based around oddness everything rather actual punchlines first odd pretty funny movie progressed find joke oddness funny anymore low budget film thats never problem pretty interesting character eventually lost interest imagine film would appeal stoner currently partaking something similar better try brother another planet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1mkQDa6fS1y"
      },
      "source": [
        "We can now see that the text is all cleaned up with no HTML tags, punctuations, special characters and stopwords, and it is ready for vectorization and training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbXhBmd0fkNW"
      },
      "source": [
        "**Vectorization of reviews in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koF8WflLfWRa"
      },
      "source": [
        "# create a corpus to convert the text to mathematical forms or numeric values\n",
        "corpus = [] # empty vector\n",
        "corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEi75GMYfzhZ"
      },
      "source": [
        "Two Vectorization techniques are applied to check the discrepancy between them and the technique with the highest accuracy will be choosen.\n",
        "\n",
        "1.   CountVectorizer (Bag of Words (BoW) Model)\n",
        "2.   Tfidf Vectorizer (Bag of Words (BoW) Model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz2qNjvBgL8R"
      },
      "source": [
        "CountVectorizer (Bag of Words (BoW) Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs7nxKM5fYV3",
        "outputId": "69be3444-b3c3-4c58-cd2f-690885f0abb8"
      },
      "source": [
        "# importing CountVectorizer to perform vectorization\n",
        "# Data becomes numeric with 1,2,3s based on the number of times\n",
        "# they appear in the text\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "review_count_vect = count_vect.fit_transform(corpus) # fitting this technique\n",
        "# onto the corpus\n",
        "review_count_vect.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtNgE2ihgjrq"
      },
      "source": [
        "Tfidf Vectorizer (Bag of Words (BoW) Model)\n",
        "\n",
        "\n",
        "1.   Text Frequency (TF): how many times a word appears in a review\n",
        "2.   Inverse Document Frequency (IDF): log(# of text in corpus/# of documents text the term)\n",
        "\n",
        "TF-IDF score = TF*IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbJdB-xdfs_L",
        "outputId": "c18aea41-353e-4b43-f846-f1f41e2aa889"
      },
      "source": [
        "# importing TfidfVectorizer to perform vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# IDF acts as a diminishing factor and diminishes the weights of terms that\n",
        "# occurs frequently in the text and increases the weights of the terms \n",
        "# that occurs rarely.\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "review_tfidf_vect = tfidf_vect.fit_transform(corpus)\n",
        "review_tfidf_vect.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12700013, 0.12700013, 0.12700013, 0.12700013, 0.12700013,\n",
              "        0.12700013, 0.12700013, 0.12700013, 0.12700013, 0.12700013,\n",
              "        0.12700013, 0.12700013, 0.12700013, 0.12700013, 0.38100038,\n",
              "        0.12700013, 0.12700013, 0.25400025, 0.12700013, 0.12700013,\n",
              "        0.12700013, 0.12700013, 0.12700013, 0.12700013, 0.12700013,\n",
              "        0.12700013, 0.12700013, 0.12700013, 0.25400025, 0.12700013,\n",
              "        0.12700013, 0.12700013, 0.12700013, 0.25400025, 0.12700013,\n",
              "        0.12700013, 0.12700013, 0.12700013, 0.12700013, 0.12700013,\n",
              "        0.12700013, 0.12700013, 0.12700013, 0.12700013, 0.12700013]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNNiX22FhiLe"
      },
      "source": [
        "So far, the techniques mentioned above have been implemented on only one sample review. Now, the above techniques will be applied on all the reviews in the dataset. As there is no test dataset, the dataset is split into 25% of the data as test dataset to test the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeP_zmurfuOi"
      },
      "source": [
        "# splitting the dataset into training and test data\n",
        "# 25% of the data as test dataset and pseudo random generator\n",
        "# to randomly distribute the reviews to each dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset, test_dataset, traindata_label, testdata_label = train_test_split(dataset['review'], dataset['sentiment'], test_size=0.25, random_state=42)\n",
        "# Convert the sentiments (target column) to numeric forms (1s and 0s) for simplicity\n",
        "traindata_label = (traindata_label.replace({'positive': 1, 'negative': 0})).values\n",
        "testdata_label  = (testdata_label.replace({'positive': 1, 'negative': 0})).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYVdszribVc"
      },
      "source": [
        "Implementation of text cleaning techniques discussed above on the whole dataset and build the train and test corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMNP8t9MfxtL"
      },
      "source": [
        "# test and training corpus\n",
        "train_corpus = []\n",
        "test_corpus  = []\n",
        "\n",
        "# text cleaning techniques for training dataset\n",
        "for i in range(train_dataset.shape[0]):\n",
        "    soup = BeautifulSoup(train_dataset.iloc[i], \"html.parser\")\n",
        "    review = soup.get_text()\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
        "    lemma = WordNetLemmatizer()\n",
        "    review = [lemma.lemmatize(word) for word in review]\n",
        "    review = ' '.join(review)\n",
        "    train_corpus.append(review)\n",
        "    \n",
        "# text cleaning techniques for test dataset\n",
        "for j in range(test_dataset.shape[0]):\n",
        "    soup = BeautifulSoup(test_dataset.iloc[j], \"html.parser\")\n",
        "    review = soup.get_text()\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
        "    lemma = WordNetLemmatizer()\n",
        "    review = [lemma.lemmatize(word) for word in review]\n",
        "    review = ' '.join(review)\n",
        "    test_corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RWTe9QKjIjf"
      },
      "source": [
        "Validate one sample entry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "EWY9dz_Lf4eR",
        "outputId": "b6e92cb3-65fd-44a0-932c-3529ea8a9dfc"
      },
      "source": [
        "# training corpus\n",
        "train_corpus[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'kind movie want good suck first thing hell punk trying school think kid seem realize gravity situation deker guy say girl responsibility ask want go back right give gun wheel chair dude want go alone repair phone line responsibility understand poor actor must pay food give money take make stupid movie like give money charity oh yea none know aim stupid punk guy shoot cafeteria nowhere like crazy want look professional suck one thing believe emergency exit school kid trying several door locked happens fire dumas security guard dead illegal emergency exit school anyway lot say would long spent time life watch crap'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "t8we-dQFhBAo",
        "outputId": "d3382e9a-514f-4f93-96dc-cb81ab518d53"
      },
      "source": [
        "# test corpus\n",
        "test_corpus[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'many television show appeal quite many different kind fan like farscape know youngster year old fan male female many different country think adore v miniseries element found almost every show v character driven drama could australian soap opera yet episode science fact fiction would give even hardiest trekkie run money brainbender stake wormhole theory time travel true equational form magnificent embrace culture map possibility endless multiple star therefore thousand planet choose broad scope would expected nothing would able keep illusion long farscape really come element succeeds others failed especially like star trek universe practically zero kaos element ran idea pretty quickly kept rehashing course season manage keep audience attention using good continuity constant character evolution multiple thread every episode unique personal touch camera specific certain character group within whole structure allows extremely large area subject matter loyalty forged broken many way many many issue happened see pilot premiere passing keep tuning see crichton would ever get girl seeing television delighted see available dvd admit thing kept sane whilst hour night shift developed chronic insomnia farscape thing get extremely long night favour watch pilot see mean farscape comet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVm5dxK_jSIQ"
      },
      "source": [
        "Vectorize the training and test corpus using TFIDF technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N4bV4eQhBbx"
      },
      "source": [
        "# lower and upper boundary of the range of n-values for different word n-grams to be extracted.\n",
        "# (1,3) means unigrams and trigrams.\n",
        "tfidf_vect = TfidfVectorizer(ngram_range=(1, 3))\n",
        "# fitting training corpus and test corpus onto TFIDF Vectorizer\n",
        "tfidf_vect_train = tfidf_vect.fit_transform(train_corpus)\n",
        "tfidf_vect_test = tfidf_vect.transform(test_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-M9_5oDjjs6"
      },
      "source": [
        "**First model: LinearSVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPbXJ0_e1o2L"
      },
      "source": [
        "# importing LinearSVC library and fitting the data onto the model\n",
        "from sklearn.svm import LinearSVC\n",
        "# C: float; regularization parameter, must be positive.\n",
        "# random_state: controls pseudo random number generation for\n",
        "# shuffling data for dual coordinate descent. \n",
        "linear_SVC = LinearSVC(C = 0.5, random_state = 42)\n",
        "linear_SVC.fit(tfidf_vect_train, traindata_label)\n",
        "predict = linear_SVC.predict(tfidf_vect_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwyGVNxUj8wR"
      },
      "source": [
        "LinearSVC with TFIDF Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDVSEIlY1q70",
        "outputId": "98e263ea-18b6-4129-d55a-4ca499dc5985"
      },
      "source": [
        "# Check the performance of the model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(\"Classification Report of LinearSVC model with TFIDF: \\n\", classification_report(testdata_label, predict,target_names=['Negative','Positive']))\n",
        "print(\"Confusion Matrix of LinearSVC with TFIDF: \\n\", confusion_matrix(testdata_label, predict))\n",
        "print(\"Accuracy of LinearSVC with TFIDF: \\n\", accuracy_score(testdata_label, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report of LinearSVC model with TFIDF: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.91      0.89      0.90      6157\n",
            "    Positive       0.89      0.92      0.91      6343\n",
            "\n",
            "    accuracy                           0.90     12500\n",
            "   macro avg       0.90      0.90      0.90     12500\n",
            "weighted avg       0.90      0.90      0.90     12500\n",
            "\n",
            "Confusion Matrix of LinearSVC with TFIDF: \n",
            " [[5467  690]\n",
            " [ 524 5819]]\n",
            "Accuracy of LinearSVC with TFIDF: \n",
            " 0.90288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "aNQuGq5D0ECY",
        "outputId": "97861491-7d08-433e-d4c8-4ba335f33430"
      },
      "source": [
        "import seaborn as sns\n",
        "con_matrix = confusion_matrix(testdata_label, predict)\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(con_matrix, cmap= \"Blues\", linecolor = 'black', linewidth = 1, annot = True, fmt= '', xticklabels = ['Negative Reviews','Positive Reviews'], yticklabels = ['Negative Reviews','Positive Reviews'])\n",
        "plt.xlabel(\"Predicted Sentiment\")\n",
        "plt.ylabel(\"Actual Sentiment\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Actual Sentiment')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUMmbpHMkAO5"
      },
      "source": [
        "LinearSVC with CountVectorizer (binary=False) Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnVcRJJo1sIO"
      },
      "source": [
        "# fitting the data onto the model using CountVectorizer technique\n",
        "# binary = False -> If you set binary=True then CountVectorizer no longer uses the counts of terms/tokens.\n",
        "# If a token is present in a document, it is 1, if absent it is 0 regardless of its frequency of occurrence.\n",
        "# So you will be dealing with just binary values. By default, binary=False.\n",
        "# If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.\n",
        "count_vect = CountVectorizer(ngram_range=(1, 3), binary = False) # lower and upper boundary\n",
        "# of the range of n-values for different word n-grams to be extracted.\n",
        "# (1,3) means unigrams and trigrams.\n",
        "count_vect_train = count_vect.fit_transform(train_corpus)\n",
        "count_vect_test = count_vect.transform(test_corpus)\n",
        "linear_SVC_count = LinearSVC(C = 0.5, random_state = 42, max_iter = 5000)\n",
        "linear_SVC_count.fit(count_vect_train, traindata_label)\n",
        "predict_count = linear_SVC_count.predict(count_vect_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMnPPvdK1tUA",
        "outputId": "aa9b4fa3-3acf-4214-8806-24e8ace8b4ea"
      },
      "source": [
        "# Check the performance of the model\n",
        "print(\"Classification Report of LinearSVC with CountVectorizer: \\n\", classification_report(testdata_label, predict_count,target_names=['Negative','Positive']))\n",
        "print(\"Confusion Matrix of LinearSVC with CountVectorizer: \\n\", confusion_matrix(testdata_label, predict_count))\n",
        "print(\"Accuracy of LinearSVC with CountVectorizer: \\n\", accuracy_score(testdata_label, predict_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report of LinearSVC with CountVectorizer: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.90      0.89      0.90      6157\n",
            "    Positive       0.90      0.90      0.90      6343\n",
            "\n",
            "    accuracy                           0.90     12500\n",
            "   macro avg       0.90      0.90      0.90     12500\n",
            "weighted avg       0.90      0.90      0.90     12500\n",
            "\n",
            "Confusion Matrix of LinearSVC with CountVectorizer: \n",
            " [[5489  668]\n",
            " [ 611 5732]]\n",
            "Accuracy of LinearSVC with CountVectorizer: \n",
            " 0.89768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "eYyur7xv04gW",
        "outputId": "f0c50fb8-c8df-45a4-a489-9639ae4c2281"
      },
      "source": [
        "con_matrix = confusion_matrix(testdata_label, predict_count)\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(con_matrix,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = ['Negative Reviews','Positive Reviews'] , yticklabels = ['Negative Reviews','Positive Reviews'])\n",
        "plt.xlabel(\"Predicted Sentiment\")\n",
        "plt.ylabel(\"Actual Sentiment\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Actual Sentiment')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejLBmsFZkWWm"
      },
      "source": [
        "From the above results, we can observe that **LinearSVC with TFIDF vectorization** gives the maximum accuracy and the outcome on our test dataset can be observed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u-GZHPfDaGsl",
        "outputId": "ea960441-0187-4c97-c1de-15ae13203208"
      },
      "source": [
        "# prediction of data using the above model\n",
        "predict_dataset = test_dataset.copy()\n",
        "predict_dataset = pd.DataFrame(predict_dataset)\n",
        "# setting columns of the predicted outcomes on the dataset\n",
        "predict_dataset.columns = ['Review']\n",
        "predict_dataset = predict_dataset.reset_index()\n",
        "predict_dataset = predict_dataset.drop(['index'], axis=1)\n",
        "# set the maximum column width to 100000 or more to view the complete review\n",
        "pd.set_option('display.max_colwidth',100000)\n",
        "pd.set_option('max_rows', 200)\n",
        "predict_dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not many television shows appeal to quite as many different kinds of fans like Farscape does...I know youngsters and 30/40+ years old;fans both Male and Female in as many different countries as you can think of that just adore this T.V miniseries. It has elements that can be found in almost every other show on T.V, character driven drama that could be from an Australian soap opera; yet in the same episode it has science fact &amp; fiction that would give even the hardiest \"Trekkie\" a run for his money in the brainbender stakes! Wormhole theory, Time Travel in true equational form...Magnificent. It embraces cultures from all over the map as the possibilities are endless having multiple stars and therefore thousands of planets to choose from.&lt;br /&gt;&lt;br /&gt;With such a broad scope; it would be expected that nothing would be able to keep up the illusion for long, but here is where \"Farscape\" really comes into it's own element...It succeeds where all others have failed, especially the likes of Star Trek (a universe with practically zero Kaos element!) They ran out of ideas pretty quickly + kept rehashing them! Over the course of 4 seasons they manage to keep the audience's attention using good continuity and constant character evolution with multiple threads to every episode with unique personal touches to camera that are specific to certain character groups within the whole. This structure allows for an extremely large area of subject matter as loyalties are forged and broken in many ways on many many issues. I happened to see the pilot (Premiere) in passing and just had to keep tuning in after that to see if Crichton would ever \"Get the girl\", after seeing them all on television I was delighted to see them available on DVD &amp; I have to admit that it was the only thing that kept me sane whilst I had to do a 12 hour night shift and developed chronic insomnia...Farscape was the only thing to get me through those extremely long nights...&lt;br /&gt;&lt;br /&gt;Do yourself a favour; Watch the pilot and see what I mean...&lt;br /&gt;&lt;br /&gt;Farscape Comet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film quickly gets to a major chase scene with ever increasing destruction. The first really bad thing is the guy hijacking Steven Seagal would have been beaten to pulp by Seagal's driving, but that probably would have ended the whole premise for the movie.&lt;br /&gt;&lt;br /&gt;It seems like they decided to make all kinds of changes in the movie plot, so just plan to enjoy the action, and do not expect a coherent plot. Turn any sense of logic you may have, it will reduce your chance of getting a headache.&lt;br /&gt;&lt;br /&gt;I does give me some hope that Steven Seagal is trying to move back towards the type of characters he portrayed in his more popular movies.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jane Austen would definitely approve of this one!&lt;br /&gt;&lt;br /&gt;Gwyneth Paltrow does an awesome job capturing the attitude of Emma. She is funny without being excessively silly, yet elegant. She puts on a very convincing British accent (not being British myself, maybe I'm not the best judge, but she fooled me...she was also excellent in \"Sliding Doors\"...I sometimes forget she's American ~!). &lt;br /&gt;&lt;br /&gt;Also brilliant are Jeremy Northam and Sophie Thompson and Phyllida Law (Emma Thompson's sister and mother) as the Bates women. They nearly steal the show...and Ms. Law doesn't even have any lines!&lt;br /&gt;&lt;br /&gt;Highly recommended.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Expectations were somewhat high for me when I went to see this movie, after all I thought Steve Carell could do no wrong coming off of great movies like Anchorman, The 40 Year-Old Virgin, and Little Miss Sunshine. Boy, was I wrong.&lt;br /&gt;&lt;br /&gt;I'll start with what is right with this movie: at certain points Steve Carell is allowed to be Steve Carell. There are a handful of moments in the film that made me laugh, and it's due almost entirely to him being given the wiggle-room to do his thing. He's an undoubtedly talented individual, and it's a shame that he signed on to what turned out to be, in my opinion, a total train-wreck.&lt;br /&gt;&lt;br /&gt;With that out of the way, I'll discuss what went horrifyingly wrong.&lt;br /&gt;&lt;br /&gt;The film begins with Dan Burns, a widower with three girls who is being considered for a nationally syndicated advice column. He prepares his girls for a family reunion, where his extended relatives gather for some time with each other.&lt;br /&gt;&lt;br /&gt;The family is high atop the list of things that make this an awful movie. No family behaves like this. It's almost as if they've been transported from Pleasantville or Leave it to Beaver. They are a caricature of what we think a family is when we're 7. It reaches the point where they become obnoxious and simply frustrating. Touch football, crossword puzzle competitions, family bowling, and talent shows ARE NOT HOW ACTUAL PEOPLE BEHAVE. It's almost sickening.&lt;br /&gt;&lt;br /&gt;Another big flaw is the woman Carell is supposed to be falling for. Observing her in her first scene with Steve Carell is like watching a stroke victim trying to be rehabilitated. What I imagine is supposed to be unique and original in this woman comes off as mildly retarded.&lt;br /&gt;&lt;br /&gt;It makes me think that this movie is taking place on another planet. I left the theater wondering what I just saw. After thinking further, I don't think it was much.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I've watched this movie on a fairly regular basis for most of my life, and it never gets old. For all the snide remarks and insults (mostly from David Spade), \"Tommy Boy\" has a giant heart. And that's what keeps this movie funny after all these years.&lt;br /&gt;&lt;br /&gt;Tommy Callahan (Chris Farley) is the son of Big Tom Callahan (Brian Dennehy), master car parts salesman, and has ridden on that all his life. But after his died dies on his wedding day, Tommy learns that the company is in debt, and about to be bought by Ray Zalinsky (Dan Akroyd), the owner of a huge car parts company. So in order to save the company, Tommy has to go on the road to sell the company's new brake pads. Along for the ride, though not by choice, is Richard Hayden (David Spade) a former classmate of Tommy's who was Big Tom's right-hand man.&lt;br /&gt;&lt;br /&gt;The movie rides on the chemistry between the two SNL stars (and real-life best friends) Chris Farley and David Spade. The duo has enough comic energy going between them to power the world. It's the big, dumb guy versus the smart little guy. It works, and some of their scenes are unforgettably funny. Farley and Spade are actually decent dramatic actors as well. Although the film is primarily a comedy, it has its fair share of drama, but Spade and especially Farley are just as good there as when they're making the audience laugh.&lt;br /&gt;&lt;br /&gt;Forgive me, but I have to talk about Chris Farley a little more. I read his biography (\"The Chris Farley Show: A Biography in Three Acts,\" for anyone who cares), and understanding who Chris was in real life made this movie more special to me. Chris Farley was a genuinely good person who struggled, and ultimately failed to conquer his addictions. Although this was the first movie he had a major role in, it is his best film. It really showed who he was, and just how much talent he had. Knowing Chris's story adds another layer to this movie, although it doesn't make it any less funny.&lt;br /&gt;&lt;br /&gt;Farley and Spade are matched with a good on screen cast. Rob Lowe is suitably slimy as Tommy's \"new brother,\" and Bo Derek is solid as his step-mother. Brian Dennehy is great as Big Tom. Dennehy makes it easy to believe that they're father in son. Big Tom is just as crazy as his son, although he's smarter and more mature. Dan Akroyd gives one of his best performances as Zalinsky, giving Tommy the hard truth behind advertising. Julie Warner is also good as Tommy's love interest, Michelle.&lt;br /&gt;&lt;br /&gt;For me, Peter Segal is one of the great comedy directors. He keeps the pace quick and energetic, but most importantly, he knows how to make comedy funny. He doesn't belabor the jokes, and he understands that funny actors know what they're doing and he allows them to do it. But Segal goes a step further. He gives \"Tommy Boy\" a friendly, almost nostalgic tone that both tugs the heartstrings (genuinely) and tickles the funnybone.&lt;br /&gt;&lt;br /&gt;Critics didn't like \"Tommy Boy.\" Shame on them. A movie doesn't have to be super sophisticated or subversively intellectual to be funny (God forbid Farley and Spade were forced to do muted comedy a la \"The Office\"). This is a great movie and one of my all-time favorites.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>For once a story of hope highlighted over the tragic reality our youth face. Favela Rising draws one into a scary, unsafe and unfair world and shows through beautiful color and moving music how one man and his dedicated friends choose not to accept that world and change it through action and art. An entertaining, interesting, emotional, aesthetically beautiful film. I showed this film to numerous high school students as well who all live in neighborhoods with poverty and and gun violence and they were enamored with Anderson, the protagonist. I recommend this film to all ages over 13 (due to subtitles and some images of death) from all backgrounds.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Okay, I didn't get the Purgatory thing the first time I watched this episode. It seemed like something significant was going on that I couldn't put my finger on. This time those Costa Mesa fires on TV really caught my attention- and it helped that I was just writing an essay on Inferno! But let me see what HASN'T been discussed yet...&lt;br /&gt;&lt;br /&gt;A TWOP review mentioned that Tony had 7 flights of stairs to go down because of the broken elevator. Yeah, 7 is a significant number for lots of reasons, especially religious, but here's one more for ya. On a hunch I consulted wikipedia, and guess what Dante divided into 7 levels? Purgatorio. Excluding ante-Purgatory and Paradise. (The stuff at the bottom of the stairs and... what Tony can't get to.) &lt;br /&gt;&lt;br /&gt;On to the allegedly \"random\" monk-slap scene. As soon as the monks appeared, it fit perfectly in place with Tony trying to get out of Purgatory. You can tell he got worried when that Christian commercial (death, disease, and sin) came on, and he's getting more and more desperate because Christian heaven is looking kinda iffy for him. By the time he meets the monks he's thinking \"hey maybe these guys can help me?\" which sounds like contemplating other religions (e.g. Buddhism) and wondering if some other path could take him to \"salvation\". Not that Tony is necessarily literally thinking about becoming a Buddhist, but it appears Finnerty tried that (and messed up). That slap in the face basically tells Tony there's no quick fix- as in, no, you can't suddenly embrace Buddhism and get out of here. &lt;br /&gt;&lt;br /&gt;Tony was initially not too concerned about getting to heaven. But at the \"conference entrance\", he realizes that's not going to be so easy for him. At first I saw the name vs. driver's license problem as Tony having led sort of a double life, what with the killing people and sleeping around that he kept secret from most people. He feels free to have an affair with quasi-Melfi because \"he's Kevin Finnerty\". He figures out that he CAN fool some people with KF's cards, like hotel receptionists, but it won't get him out of Purgatory. Those helicopters- the helicopters of Heaven?- are keeping track of him and everything he does.&lt;br /&gt;&lt;br /&gt;After reading all the theories on \"inFinnerty\", though, it seems like KF's identity is a reminder of the infinite different paths Tony could've taken in his life. Possibly along with the car joke involving Infiniti's that made no sense to me otherwise. Aaaand at that point my brain fizzles out.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I was very disappointed with this series. It had lots of cool graphics and that's about it. The level of detail it went into was minimal, and I always got the feeling the audience was being patronized -- there was a lot of what seemed to me as \"This is extremely cool but we're not going to explain it in further detail because you won't get it anyway. Let's just show you some pretty pictures to entertain you.\" The host would drop interesting-sounding words such as \"sparticles\" and \"super-symmetry\" without any attempt at explaining what it was. We had to look it up on Wikipedia.&lt;br /&gt;&lt;br /&gt;Furthermore, I know quite a bit about superstrings (for a layman) and I found their explanations were convoluted and could have been so much better. They could have chosen MUCH better examples to explain concepts, but instead, the examples they used were confusing and further obscured the subject.&lt;br /&gt;&lt;br /&gt;Additionally, I got so sick of the repetitiveness. They could easily have condensed the series into one episode if they had cut out all the repetition. They must have shown the clips of the Quantum Caf about 8 times. The host kept saying the same things over and over and over again. I can't remember how many times he said \"The universe is made out of tiny little vibrating strings.\" It's like they were trying to brainwash us into just accepting \"superstrings are the best thing since sliced bread.\"&lt;br /&gt;&lt;br /&gt;Finally, the show ended off with an unpleasant sense of a \"competition\" between Fermilab and CERN, clearly biased towards Fermilab. This is supposed to be an educational program about quantum physics, not about whether the US is better than Europe or vice versa! I also felt that was part of the patronizing -- \"Audiences need to see some conflict to remain interested.\" Please. Give me a little more credit than that.&lt;br /&gt;&lt;br /&gt;Overall, 2 thumbs down :-(</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The first 30 minutes of Tinseltown had my finger teetering on the remote, poised to flick around to watch something else. The premise of two writers, down on their luck, living in a self-storage-space \"bin\" was mildly amusing, but, painfully bland.&lt;br /&gt;&lt;br /&gt;The introduction of the character, played by Joe Pantoliano - the big deal movie guy, that lives in the park and sleeps in a lavatory, offered hope and I decided to give it a few more minutes. And then a few more until Kristy Swansons introduction as a budding film director &amp; borderline nymphomaniac, added a bit of spice. Her solid acting performance raised her presence above and beyond just a very welcome eye-candy inclusion.&lt;br /&gt;&lt;br /&gt;Ultimately, the obvious low-budget impacts on the film with poorly shot scenes, stuttured pace and slapstick handling of certain moments. Some of my favourite movies of all time have been low budget, Whithnail &amp; I being one that also deals with 2 guys with a dream, but down on their luck.&lt;br /&gt;&lt;br /&gt;However, for my money, the actors save Tinseltown from the \"Terrible movie\" archives and just about nudges it into the \"could have been a cult movie\" archives. I laughed out loud at some of the scenes involving Joe Pantoliano's character. In particular, the penultimate scenes in the terribly clichd, but still funny, rich-but-screwed-up characters house, where the story unravels towards it's final moments.&lt;br /&gt;&lt;br /&gt;I can see how Tinseltown was a great stage play and while the film-makers did their best to translate this to celluloid, it simply didn't work and while I laughed out loud at some of scenes and one liners, I think the first 30 minutes dulled my senses and expectations to such a degree I would have laughed at anything.&lt;br /&gt;&lt;br /&gt;Unless you're stuck for a novelty coffee coaster, don't pick this up if you see it in a bargain bucket.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Review\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10\n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Not many television shows appeal to quite as many different kinds of fans like Farscape does...I know youngsters and 30/40+ years old;fans both Male and Female in as many different countries as you can think of that just adore this T.V miniseries. It has elements that can be found in almost every other show on T.V, character driven drama that could be from an Australian soap opera; yet in the same episode it has science fact & fiction that would give even the hardiest \"Trekkie\" a run for his money in the brainbender stakes! Wormhole theory, Time Travel in true equational form...Magnificent. It embraces cultures from all over the map as the possibilities are endless having multiple stars and therefore thousands of planets to choose from.<br /><br />With such a broad scope; it would be expected that nothing would be able to keep up the illusion for long, but here is where \"Farscape\" really comes into it's own element...It succeeds where all others have failed, especially the likes of Star Trek (a universe with practically zero Kaos element!) They ran out of ideas pretty quickly + kept rehashing them! Over the course of 4 seasons they manage to keep the audience's attention using good continuity and constant character evolution with multiple threads to every episode with unique personal touches to camera that are specific to certain character groups within the whole. This structure allows for an extremely large area of subject matter as loyalties are forged and broken in many ways on many many issues. I happened to see the pilot (Premiere) in passing and just had to keep tuning in after that to see if Crichton would ever \"Get the girl\", after seeing them all on television I was delighted to see them available on DVD & I have to admit that it was the only thing that kept me sane whilst I had to do a 12 hour night shift and developed chronic insomnia...Farscape was the only thing to get me through those extremely long nights...<br /><br />Do yourself a favour; Watch the pilot and see what I mean...<br /><br />Farscape Comet\n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The film quickly gets to a major chase scene with ever increasing destruction. The first really bad thing is the guy hijacking Steven Seagal would have been beaten to pulp by Seagal's driving, but that probably would have ended the whole premise for the movie.<br /><br />It seems like they decided to make all kinds of changes in the movie plot, so just plan to enjoy the action, and do not expect a coherent plot. Turn any sense of logic you may have, it will reduce your chance of getting a headache.<br /><br />I does give me some hope that Steven Seagal is trying to move back towards the type of characters he portrayed in his more popular movies.\n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Jane Austen would definitely approve of this one!<br /><br />Gwyneth Paltrow does an awesome job capturing the attitude of Emma. She is funny without being excessively silly, yet elegant. She puts on a very convincing British accent (not being British myself, maybe I'm not the best judge, but she fooled me...she was also excellent in \"Sliding Doors\"...I sometimes forget she's American ~!). <br /><br />Also brilliant are Jeremy Northam and Sophie Thompson and Phyllida Law (Emma Thompson's sister and mother) as the Bates women. They nearly steal the show...and Ms. Law doesn't even have any lines!<br /><br />Highly recommended.\n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Expectations were somewhat high for me when I went to see this movie, after all I thought Steve Carell could do no wrong coming off of great movies like Anchorman, The 40 Year-Old Virgin, and Little Miss Sunshine. Boy, was I wrong.<br /><br />I'll start with what is right with this movie: at certain points Steve Carell is allowed to be Steve Carell. There are a handful of moments in the film that made me laugh, and it's due almost entirely to him being given the wiggle-room to do his thing. He's an undoubtedly talented individual, and it's a shame that he signed on to what turned out to be, in my opinion, a total train-wreck.<br /><br />With that out of the way, I'll discuss what went horrifyingly wrong.<br /><br />The film begins with Dan Burns, a widower with three girls who is being considered for a nationally syndicated advice column. He prepares his girls for a family reunion, where his extended relatives gather for some time with each other.<br /><br />The family is high atop the list of things that make this an awful movie. No family behaves like this. It's almost as if they've been transported from Pleasantville or Leave it to Beaver. They are a caricature of what we think a family is when we're 7. It reaches the point where they become obnoxious and simply frustrating. Touch football, crossword puzzle competitions, family bowling, and talent shows ARE NOT HOW ACTUAL PEOPLE BEHAVE. It's almost sickening.<br /><br />Another big flaw is the woman Carell is supposed to be falling for. Observing her in her first scene with Steve Carell is like watching a stroke victim trying to be rehabilitated. What I imagine is supposed to be unique and original in this woman comes off as mildly retarded.<br /><br />It makes me think that this movie is taking place on another planet. I left the theater wondering what I just saw. After thinking further, I don't think it was much.\n",
              "5  I've watched this movie on a fairly regular basis for most of my life, and it never gets old. For all the snide remarks and insults (mostly from David Spade), \"Tommy Boy\" has a giant heart. And that's what keeps this movie funny after all these years.<br /><br />Tommy Callahan (Chris Farley) is the son of Big Tom Callahan (Brian Dennehy), master car parts salesman, and has ridden on that all his life. But after his died dies on his wedding day, Tommy learns that the company is in debt, and about to be bought by Ray Zalinsky (Dan Akroyd), the owner of a huge car parts company. So in order to save the company, Tommy has to go on the road to sell the company's new brake pads. Along for the ride, though not by choice, is Richard Hayden (David Spade) a former classmate of Tommy's who was Big Tom's right-hand man.<br /><br />The movie rides on the chemistry between the two SNL stars (and real-life best friends) Chris Farley and David Spade. The duo has enough comic energy going between them to power the world. It's the big, dumb guy versus the smart little guy. It works, and some of their scenes are unforgettably funny. Farley and Spade are actually decent dramatic actors as well. Although the film is primarily a comedy, it has its fair share of drama, but Spade and especially Farley are just as good there as when they're making the audience laugh.<br /><br />Forgive me, but I have to talk about Chris Farley a little more. I read his biography (\"The Chris Farley Show: A Biography in Three Acts,\" for anyone who cares), and understanding who Chris was in real life made this movie more special to me. Chris Farley was a genuinely good person who struggled, and ultimately failed to conquer his addictions. Although this was the first movie he had a major role in, it is his best film. It really showed who he was, and just how much talent he had. Knowing Chris's story adds another layer to this movie, although it doesn't make it any less funny.<br /><br />Farley and Spade are matched with a good on screen cast. Rob Lowe is suitably slimy as Tommy's \"new brother,\" and Bo Derek is solid as his step-mother. Brian Dennehy is great as Big Tom. Dennehy makes it easy to believe that they're father in son. Big Tom is just as crazy as his son, although he's smarter and more mature. Dan Akroyd gives one of his best performances as Zalinsky, giving Tommy the hard truth behind advertising. Julie Warner is also good as Tommy's love interest, Michelle.<br /><br />For me, Peter Segal is one of the great comedy directors. He keeps the pace quick and energetic, but most importantly, he knows how to make comedy funny. He doesn't belabor the jokes, and he understands that funny actors know what they're doing and he allows them to do it. But Segal goes a step further. He gives \"Tommy Boy\" a friendly, almost nostalgic tone that both tugs the heartstrings (genuinely) and tickles the funnybone.<br /><br />Critics didn't like \"Tommy Boy.\" Shame on them. A movie doesn't have to be super sophisticated or subversively intellectual to be funny (God forbid Farley and Spade were forced to do muted comedy a la \"The Office\"). This is a great movie and one of my all-time favorites.\n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            For once a story of hope highlighted over the tragic reality our youth face. Favela Rising draws one into a scary, unsafe and unfair world and shows through beautiful color and moving music how one man and his dedicated friends choose not to accept that world and change it through action and art. An entertaining, interesting, emotional, aesthetically beautiful film. I showed this film to numerous high school students as well who all live in neighborhoods with poverty and and gun violence and they were enamored with Anderson, the protagonist. I recommend this film to all ages over 13 (due to subtitles and some images of death) from all backgrounds.\n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Okay, I didn't get the Purgatory thing the first time I watched this episode. It seemed like something significant was going on that I couldn't put my finger on. This time those Costa Mesa fires on TV really caught my attention- and it helped that I was just writing an essay on Inferno! But let me see what HASN'T been discussed yet...<br /><br />A TWOP review mentioned that Tony had 7 flights of stairs to go down because of the broken elevator. Yeah, 7 is a significant number for lots of reasons, especially religious, but here's one more for ya. On a hunch I consulted wikipedia, and guess what Dante divided into 7 levels? Purgatorio. Excluding ante-Purgatory and Paradise. (The stuff at the bottom of the stairs and... what Tony can't get to.) <br /><br />On to the allegedly \"random\" monk-slap scene. As soon as the monks appeared, it fit perfectly in place with Tony trying to get out of Purgatory. You can tell he got worried when that Christian commercial (death, disease, and sin) came on, and he's getting more and more desperate because Christian heaven is looking kinda iffy for him. By the time he meets the monks he's thinking \"hey maybe these guys can help me?\" which sounds like contemplating other religions (e.g. Buddhism) and wondering if some other path could take him to \"salvation\". Not that Tony is necessarily literally thinking about becoming a Buddhist, but it appears Finnerty tried that (and messed up). That slap in the face basically tells Tony there's no quick fix- as in, no, you can't suddenly embrace Buddhism and get out of here. <br /><br />Tony was initially not too concerned about getting to heaven. But at the \"conference entrance\", he realizes that's not going to be so easy for him. At first I saw the name vs. driver's license problem as Tony having led sort of a double life, what with the killing people and sleeping around that he kept secret from most people. He feels free to have an affair with quasi-Melfi because \"he's Kevin Finnerty\". He figures out that he CAN fool some people with KF's cards, like hotel receptionists, but it won't get him out of Purgatory. Those helicopters- the helicopters of Heaven?- are keeping track of him and everything he does.<br /><br />After reading all the theories on \"inFinnerty\", though, it seems like KF's identity is a reminder of the infinite different paths Tony could've taken in his life. Possibly along with the car joke involving Infiniti's that made no sense to me otherwise. Aaaand at that point my brain fizzles out.\n",
              "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I was very disappointed with this series. It had lots of cool graphics and that's about it. The level of detail it went into was minimal, and I always got the feeling the audience was being patronized -- there was a lot of what seemed to me as \"This is extremely cool but we're not going to explain it in further detail because you won't get it anyway. Let's just show you some pretty pictures to entertain you.\" The host would drop interesting-sounding words such as \"sparticles\" and \"super-symmetry\" without any attempt at explaining what it was. We had to look it up on Wikipedia.<br /><br />Furthermore, I know quite a bit about superstrings (for a layman) and I found their explanations were convoluted and could have been so much better. They could have chosen MUCH better examples to explain concepts, but instead, the examples they used were confusing and further obscured the subject.<br /><br />Additionally, I got so sick of the repetitiveness. They could easily have condensed the series into one episode if they had cut out all the repetition. They must have shown the clips of the Quantum Caf about 8 times. The host kept saying the same things over and over and over again. I can't remember how many times he said \"The universe is made out of tiny little vibrating strings.\" It's like they were trying to brainwash us into just accepting \"superstrings are the best thing since sliced bread.\"<br /><br />Finally, the show ended off with an unpleasant sense of a \"competition\" between Fermilab and CERN, clearly biased towards Fermilab. This is supposed to be an educational program about quantum physics, not about whether the US is better than Europe or vice versa! I also felt that was part of the patronizing -- \"Audiences need to see some conflict to remain interested.\" Please. Give me a little more credit than that.<br /><br />Overall, 2 thumbs down :-(\n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The first 30 minutes of Tinseltown had my finger teetering on the remote, poised to flick around to watch something else. The premise of two writers, down on their luck, living in a self-storage-space \"bin\" was mildly amusing, but, painfully bland.<br /><br />The introduction of the character, played by Joe Pantoliano - the big deal movie guy, that lives in the park and sleeps in a lavatory, offered hope and I decided to give it a few more minutes. And then a few more until Kristy Swansons introduction as a budding film director & borderline nymphomaniac, added a bit of spice. Her solid acting performance raised her presence above and beyond just a very welcome eye-candy inclusion.<br /><br />Ultimately, the obvious low-budget impacts on the film with poorly shot scenes, stuttured pace and slapstick handling of certain moments. Some of my favourite movies of all time have been low budget, Whithnail & I being one that also deals with 2 guys with a dream, but down on their luck.<br /><br />However, for my money, the actors save Tinseltown from the \"Terrible movie\" archives and just about nudges it into the \"could have been a cult movie\" archives. I laughed out loud at some of the scenes involving Joe Pantoliano's character. In particular, the penultimate scenes in the terribly clichd, but still funny, rich-but-screwed-up characters house, where the story unravels towards it's final moments.<br /><br />I can see how Tinseltown was a great stage play and while the film-makers did their best to translate this to celluloid, it simply didn't work and while I laughed out loud at some of scenes and one liners, I think the first 30 minutes dulled my senses and expectations to such a degree I would have laughed at anything.<br /><br />Unless you're stuck for a novelty coffee coaster, don't pick this up if you see it in a bargain bucket."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x-cXqK7aIIF"
      },
      "source": [
        "# comparing the actual/original label with the predicted label\n",
        "testactual_label = testdata_label.copy()\n",
        "testactual_label = pd.DataFrame(testactual_label)\n",
        "testactual_label.columns = ['Sentiment']\n",
        "# replacing back the numeric forms of the sentiments to positive and negative respectively\n",
        "testactual_label['Sentiment'] = testactual_label['Sentiment'].replace({1: 'positive', 0: 'negative'}) \n",
        "\n",
        "# predicted sentiments\n",
        "testpredicted_label = predict.copy()\n",
        "testpredicted_label = pd.DataFrame(testpredicted_label)\n",
        "testpredicted_label.columns = ['Predicted Sentiment']\n",
        "testpredicted_label['Predicted Sentiment'] = testpredicted_label['Predicted Sentiment'].replace({1: 'positive', 0: 'negative'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sWmGDgcwa1cC",
        "outputId": "5ee54fb9-9b79-4f43-db87-fcbc0975009d"
      },
      "source": [
        "# concatenate the original and predicted labels along with its corresponding review\n",
        "test_result = pd.concat([predict_dataset, testactual_label, testpredicted_label], axis=1)\n",
        "pd.set_option('display.max_colwidth',100000)\n",
        "pd.set_option('max_rows', 200)\n",
        "test_result.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Predicted Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not many television shows appeal to quite as many different kinds of fans like Farscape does...I know youngsters and 30/40+ years old;fans both Male and Female in as many different countries as you can think of that just adore this T.V miniseries. It has elements that can be found in almost every other show on T.V, character driven drama that could be from an Australian soap opera; yet in the same episode it has science fact &amp; fiction that would give even the hardiest \"Trekkie\" a run for his money in the brainbender stakes! Wormhole theory, Time Travel in true equational form...Magnificent. It embraces cultures from all over the map as the possibilities are endless having multiple stars and therefore thousands of planets to choose from.&lt;br /&gt;&lt;br /&gt;With such a broad scope; it would be expected that nothing would be able to keep up the illusion for long, but here is where \"Farscape\" really comes into it's own element...It succeeds where all others have failed, especially the likes of Star Trek (a universe with practically zero Kaos element!) They ran out of ideas pretty quickly + kept rehashing them! Over the course of 4 seasons they manage to keep the audience's attention using good continuity and constant character evolution with multiple threads to every episode with unique personal touches to camera that are specific to certain character groups within the whole. This structure allows for an extremely large area of subject matter as loyalties are forged and broken in many ways on many many issues. I happened to see the pilot (Premiere) in passing and just had to keep tuning in after that to see if Crichton would ever \"Get the girl\", after seeing them all on television I was delighted to see them available on DVD &amp; I have to admit that it was the only thing that kept me sane whilst I had to do a 12 hour night shift and developed chronic insomnia...Farscape was the only thing to get me through those extremely long nights...&lt;br /&gt;&lt;br /&gt;Do yourself a favour; Watch the pilot and see what I mean...&lt;br /&gt;&lt;br /&gt;Farscape Comet</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film quickly gets to a major chase scene with ever increasing destruction. The first really bad thing is the guy hijacking Steven Seagal would have been beaten to pulp by Seagal's driving, but that probably would have ended the whole premise for the movie.&lt;br /&gt;&lt;br /&gt;It seems like they decided to make all kinds of changes in the movie plot, so just plan to enjoy the action, and do not expect a coherent plot. Turn any sense of logic you may have, it will reduce your chance of getting a headache.&lt;br /&gt;&lt;br /&gt;I does give me some hope that Steven Seagal is trying to move back towards the type of characters he portrayed in his more popular movies.</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jane Austen would definitely approve of this one!&lt;br /&gt;&lt;br /&gt;Gwyneth Paltrow does an awesome job capturing the attitude of Emma. She is funny without being excessively silly, yet elegant. She puts on a very convincing British accent (not being British myself, maybe I'm not the best judge, but she fooled me...she was also excellent in \"Sliding Doors\"...I sometimes forget she's American ~!). &lt;br /&gt;&lt;br /&gt;Also brilliant are Jeremy Northam and Sophie Thompson and Phyllida Law (Emma Thompson's sister and mother) as the Bates women. They nearly steal the show...and Ms. Law doesn't even have any lines!&lt;br /&gt;&lt;br /&gt;Highly recommended.</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Expectations were somewhat high for me when I went to see this movie, after all I thought Steve Carell could do no wrong coming off of great movies like Anchorman, The 40 Year-Old Virgin, and Little Miss Sunshine. Boy, was I wrong.&lt;br /&gt;&lt;br /&gt;I'll start with what is right with this movie: at certain points Steve Carell is allowed to be Steve Carell. There are a handful of moments in the film that made me laugh, and it's due almost entirely to him being given the wiggle-room to do his thing. He's an undoubtedly talented individual, and it's a shame that he signed on to what turned out to be, in my opinion, a total train-wreck.&lt;br /&gt;&lt;br /&gt;With that out of the way, I'll discuss what went horrifyingly wrong.&lt;br /&gt;&lt;br /&gt;The film begins with Dan Burns, a widower with three girls who is being considered for a nationally syndicated advice column. He prepares his girls for a family reunion, where his extended relatives gather for some time with each other.&lt;br /&gt;&lt;br /&gt;The family is high atop the list of things that make this an awful movie. No family behaves like this. It's almost as if they've been transported from Pleasantville or Leave it to Beaver. They are a caricature of what we think a family is when we're 7. It reaches the point where they become obnoxious and simply frustrating. Touch football, crossword puzzle competitions, family bowling, and talent shows ARE NOT HOW ACTUAL PEOPLE BEHAVE. It's almost sickening.&lt;br /&gt;&lt;br /&gt;Another big flaw is the woman Carell is supposed to be falling for. Observing her in her first scene with Steve Carell is like watching a stroke victim trying to be rehabilitated. What I imagine is supposed to be unique and original in this woman comes off as mildly retarded.&lt;br /&gt;&lt;br /&gt;It makes me think that this movie is taking place on another planet. I left the theater wondering what I just saw. After thinking further, I don't think it was much.</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I've watched this movie on a fairly regular basis for most of my life, and it never gets old. For all the snide remarks and insults (mostly from David Spade), \"Tommy Boy\" has a giant heart. And that's what keeps this movie funny after all these years.&lt;br /&gt;&lt;br /&gt;Tommy Callahan (Chris Farley) is the son of Big Tom Callahan (Brian Dennehy), master car parts salesman, and has ridden on that all his life. But after his died dies on his wedding day, Tommy learns that the company is in debt, and about to be bought by Ray Zalinsky (Dan Akroyd), the owner of a huge car parts company. So in order to save the company, Tommy has to go on the road to sell the company's new brake pads. Along for the ride, though not by choice, is Richard Hayden (David Spade) a former classmate of Tommy's who was Big Tom's right-hand man.&lt;br /&gt;&lt;br /&gt;The movie rides on the chemistry between the two SNL stars (and real-life best friends) Chris Farley and David Spade. The duo has enough comic energy going between them to power the world. It's the big, dumb guy versus the smart little guy. It works, and some of their scenes are unforgettably funny. Farley and Spade are actually decent dramatic actors as well. Although the film is primarily a comedy, it has its fair share of drama, but Spade and especially Farley are just as good there as when they're making the audience laugh.&lt;br /&gt;&lt;br /&gt;Forgive me, but I have to talk about Chris Farley a little more. I read his biography (\"The Chris Farley Show: A Biography in Three Acts,\" for anyone who cares), and understanding who Chris was in real life made this movie more special to me. Chris Farley was a genuinely good person who struggled, and ultimately failed to conquer his addictions. Although this was the first movie he had a major role in, it is his best film. It really showed who he was, and just how much talent he had. Knowing Chris's story adds another layer to this movie, although it doesn't make it any less funny.&lt;br /&gt;&lt;br /&gt;Farley and Spade are matched with a good on screen cast. Rob Lowe is suitably slimy as Tommy's \"new brother,\" and Bo Derek is solid as his step-mother. Brian Dennehy is great as Big Tom. Dennehy makes it easy to believe that they're father in son. Big Tom is just as crazy as his son, although he's smarter and more mature. Dan Akroyd gives one of his best performances as Zalinsky, giving Tommy the hard truth behind advertising. Julie Warner is also good as Tommy's love interest, Michelle.&lt;br /&gt;&lt;br /&gt;For me, Peter Segal is one of the great comedy directors. He keeps the pace quick and energetic, but most importantly, he knows how to make comedy funny. He doesn't belabor the jokes, and he understands that funny actors know what they're doing and he allows them to do it. But Segal goes a step further. He gives \"Tommy Boy\" a friendly, almost nostalgic tone that both tugs the heartstrings (genuinely) and tickles the funnybone.&lt;br /&gt;&lt;br /&gt;Critics didn't like \"Tommy Boy.\" Shame on them. A movie doesn't have to be super sophisticated or subversively intellectual to be funny (God forbid Farley and Spade were forced to do muted comedy a la \"The Office\"). This is a great movie and one of my all-time favorites.</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>For once a story of hope highlighted over the tragic reality our youth face. Favela Rising draws one into a scary, unsafe and unfair world and shows through beautiful color and moving music how one man and his dedicated friends choose not to accept that world and change it through action and art. An entertaining, interesting, emotional, aesthetically beautiful film. I showed this film to numerous high school students as well who all live in neighborhoods with poverty and and gun violence and they were enamored with Anderson, the protagonist. I recommend this film to all ages over 13 (due to subtitles and some images of death) from all backgrounds.</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Okay, I didn't get the Purgatory thing the first time I watched this episode. It seemed like something significant was going on that I couldn't put my finger on. This time those Costa Mesa fires on TV really caught my attention- and it helped that I was just writing an essay on Inferno! But let me see what HASN'T been discussed yet...&lt;br /&gt;&lt;br /&gt;A TWOP review mentioned that Tony had 7 flights of stairs to go down because of the broken elevator. Yeah, 7 is a significant number for lots of reasons, especially religious, but here's one more for ya. On a hunch I consulted wikipedia, and guess what Dante divided into 7 levels? Purgatorio. Excluding ante-Purgatory and Paradise. (The stuff at the bottom of the stairs and... what Tony can't get to.) &lt;br /&gt;&lt;br /&gt;On to the allegedly \"random\" monk-slap scene. As soon as the monks appeared, it fit perfectly in place with Tony trying to get out of Purgatory. You can tell he got worried when that Christian commercial (death, disease, and sin) came on, and he's getting more and more desperate because Christian heaven is looking kinda iffy for him. By the time he meets the monks he's thinking \"hey maybe these guys can help me?\" which sounds like contemplating other religions (e.g. Buddhism) and wondering if some other path could take him to \"salvation\". Not that Tony is necessarily literally thinking about becoming a Buddhist, but it appears Finnerty tried that (and messed up). That slap in the face basically tells Tony there's no quick fix- as in, no, you can't suddenly embrace Buddhism and get out of here. &lt;br /&gt;&lt;br /&gt;Tony was initially not too concerned about getting to heaven. But at the \"conference entrance\", he realizes that's not going to be so easy for him. At first I saw the name vs. driver's license problem as Tony having led sort of a double life, what with the killing people and sleeping around that he kept secret from most people. He feels free to have an affair with quasi-Melfi because \"he's Kevin Finnerty\". He figures out that he CAN fool some people with KF's cards, like hotel receptionists, but it won't get him out of Purgatory. Those helicopters- the helicopters of Heaven?- are keeping track of him and everything he does.&lt;br /&gt;&lt;br /&gt;After reading all the theories on \"inFinnerty\", though, it seems like KF's identity is a reminder of the infinite different paths Tony could've taken in his life. Possibly along with the car joke involving Infiniti's that made no sense to me otherwise. Aaaand at that point my brain fizzles out.</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I was very disappointed with this series. It had lots of cool graphics and that's about it. The level of detail it went into was minimal, and I always got the feeling the audience was being patronized -- there was a lot of what seemed to me as \"This is extremely cool but we're not going to explain it in further detail because you won't get it anyway. Let's just show you some pretty pictures to entertain you.\" The host would drop interesting-sounding words such as \"sparticles\" and \"super-symmetry\" without any attempt at explaining what it was. We had to look it up on Wikipedia.&lt;br /&gt;&lt;br /&gt;Furthermore, I know quite a bit about superstrings (for a layman) and I found their explanations were convoluted and could have been so much better. They could have chosen MUCH better examples to explain concepts, but instead, the examples they used were confusing and further obscured the subject.&lt;br /&gt;&lt;br /&gt;Additionally, I got so sick of the repetitiveness. They could easily have condensed the series into one episode if they had cut out all the repetition. They must have shown the clips of the Quantum Caf about 8 times. The host kept saying the same things over and over and over again. I can't remember how many times he said \"The universe is made out of tiny little vibrating strings.\" It's like they were trying to brainwash us into just accepting \"superstrings are the best thing since sliced bread.\"&lt;br /&gt;&lt;br /&gt;Finally, the show ended off with an unpleasant sense of a \"competition\" between Fermilab and CERN, clearly biased towards Fermilab. This is supposed to be an educational program about quantum physics, not about whether the US is better than Europe or vice versa! I also felt that was part of the patronizing -- \"Audiences need to see some conflict to remain interested.\" Please. Give me a little more credit than that.&lt;br /&gt;&lt;br /&gt;Overall, 2 thumbs down :-(</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The first 30 minutes of Tinseltown had my finger teetering on the remote, poised to flick around to watch something else. The premise of two writers, down on their luck, living in a self-storage-space \"bin\" was mildly amusing, but, painfully bland.&lt;br /&gt;&lt;br /&gt;The introduction of the character, played by Joe Pantoliano - the big deal movie guy, that lives in the park and sleeps in a lavatory, offered hope and I decided to give it a few more minutes. And then a few more until Kristy Swansons introduction as a budding film director &amp; borderline nymphomaniac, added a bit of spice. Her solid acting performance raised her presence above and beyond just a very welcome eye-candy inclusion.&lt;br /&gt;&lt;br /&gt;Ultimately, the obvious low-budget impacts on the film with poorly shot scenes, stuttured pace and slapstick handling of certain moments. Some of my favourite movies of all time have been low budget, Whithnail &amp; I being one that also deals with 2 guys with a dream, but down on their luck.&lt;br /&gt;&lt;br /&gt;However, for my money, the actors save Tinseltown from the \"Terrible movie\" archives and just about nudges it into the \"could have been a cult movie\" archives. I laughed out loud at some of the scenes involving Joe Pantoliano's character. In particular, the penultimate scenes in the terribly clichd, but still funny, rich-but-screwed-up characters house, where the story unravels towards it's final moments.&lt;br /&gt;&lt;br /&gt;I can see how Tinseltown was a great stage play and while the film-makers did their best to translate this to celluloid, it simply didn't work and while I laughed out loud at some of scenes and one liners, I think the first 30 minutes dulled my senses and expectations to such a degree I would have laughed at anything.&lt;br /&gt;&lt;br /&gt;Unless you're stuck for a novelty coffee coaster, don't pick this up if you see it in a bargain bucket.</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Review  ... Predicted Sentiment\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10  ...            negative\n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Not many television shows appeal to quite as many different kinds of fans like Farscape does...I know youngsters and 30/40+ years old;fans both Male and Female in as many different countries as you can think of that just adore this T.V miniseries. It has elements that can be found in almost every other show on T.V, character driven drama that could be from an Australian soap opera; yet in the same episode it has science fact & fiction that would give even the hardiest \"Trekkie\" a run for his money in the brainbender stakes! Wormhole theory, Time Travel in true equational form...Magnificent. It embraces cultures from all over the map as the possibilities are endless having multiple stars and therefore thousands of planets to choose from.<br /><br />With such a broad scope; it would be expected that nothing would be able to keep up the illusion for long, but here is where \"Farscape\" really comes into it's own element...It succeeds where all others have failed, especially the likes of Star Trek (a universe with practically zero Kaos element!) They ran out of ideas pretty quickly + kept rehashing them! Over the course of 4 seasons they manage to keep the audience's attention using good continuity and constant character evolution with multiple threads to every episode with unique personal touches to camera that are specific to certain character groups within the whole. This structure allows for an extremely large area of subject matter as loyalties are forged and broken in many ways on many many issues. I happened to see the pilot (Premiere) in passing and just had to keep tuning in after that to see if Crichton would ever \"Get the girl\", after seeing them all on television I was delighted to see them available on DVD & I have to admit that it was the only thing that kept me sane whilst I had to do a 12 hour night shift and developed chronic insomnia...Farscape was the only thing to get me through those extremely long nights...<br /><br />Do yourself a favour; Watch the pilot and see what I mean...<br /><br />Farscape Comet  ...            positive\n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The film quickly gets to a major chase scene with ever increasing destruction. The first really bad thing is the guy hijacking Steven Seagal would have been beaten to pulp by Seagal's driving, but that probably would have ended the whole premise for the movie.<br /><br />It seems like they decided to make all kinds of changes in the movie plot, so just plan to enjoy the action, and do not expect a coherent plot. Turn any sense of logic you may have, it will reduce your chance of getting a headache.<br /><br />I does give me some hope that Steven Seagal is trying to move back towards the type of characters he portrayed in his more popular movies.  ...            negative\n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Jane Austen would definitely approve of this one!<br /><br />Gwyneth Paltrow does an awesome job capturing the attitude of Emma. She is funny without being excessively silly, yet elegant. She puts on a very convincing British accent (not being British myself, maybe I'm not the best judge, but she fooled me...she was also excellent in \"Sliding Doors\"...I sometimes forget she's American ~!). <br /><br />Also brilliant are Jeremy Northam and Sophie Thompson and Phyllida Law (Emma Thompson's sister and mother) as the Bates women. They nearly steal the show...and Ms. Law doesn't even have any lines!<br /><br />Highly recommended.  ...            positive\n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Expectations were somewhat high for me when I went to see this movie, after all I thought Steve Carell could do no wrong coming off of great movies like Anchorman, The 40 Year-Old Virgin, and Little Miss Sunshine. Boy, was I wrong.<br /><br />I'll start with what is right with this movie: at certain points Steve Carell is allowed to be Steve Carell. There are a handful of moments in the film that made me laugh, and it's due almost entirely to him being given the wiggle-room to do his thing. He's an undoubtedly talented individual, and it's a shame that he signed on to what turned out to be, in my opinion, a total train-wreck.<br /><br />With that out of the way, I'll discuss what went horrifyingly wrong.<br /><br />The film begins with Dan Burns, a widower with three girls who is being considered for a nationally syndicated advice column. He prepares his girls for a family reunion, where his extended relatives gather for some time with each other.<br /><br />The family is high atop the list of things that make this an awful movie. No family behaves like this. It's almost as if they've been transported from Pleasantville or Leave it to Beaver. They are a caricature of what we think a family is when we're 7. It reaches the point where they become obnoxious and simply frustrating. Touch football, crossword puzzle competitions, family bowling, and talent shows ARE NOT HOW ACTUAL PEOPLE BEHAVE. It's almost sickening.<br /><br />Another big flaw is the woman Carell is supposed to be falling for. Observing her in her first scene with Steve Carell is like watching a stroke victim trying to be rehabilitated. What I imagine is supposed to be unique and original in this woman comes off as mildly retarded.<br /><br />It makes me think that this movie is taking place on another planet. I left the theater wondering what I just saw. After thinking further, I don't think it was much.  ...            negative\n",
              "5  I've watched this movie on a fairly regular basis for most of my life, and it never gets old. For all the snide remarks and insults (mostly from David Spade), \"Tommy Boy\" has a giant heart. And that's what keeps this movie funny after all these years.<br /><br />Tommy Callahan (Chris Farley) is the son of Big Tom Callahan (Brian Dennehy), master car parts salesman, and has ridden on that all his life. But after his died dies on his wedding day, Tommy learns that the company is in debt, and about to be bought by Ray Zalinsky (Dan Akroyd), the owner of a huge car parts company. So in order to save the company, Tommy has to go on the road to sell the company's new brake pads. Along for the ride, though not by choice, is Richard Hayden (David Spade) a former classmate of Tommy's who was Big Tom's right-hand man.<br /><br />The movie rides on the chemistry between the two SNL stars (and real-life best friends) Chris Farley and David Spade. The duo has enough comic energy going between them to power the world. It's the big, dumb guy versus the smart little guy. It works, and some of their scenes are unforgettably funny. Farley and Spade are actually decent dramatic actors as well. Although the film is primarily a comedy, it has its fair share of drama, but Spade and especially Farley are just as good there as when they're making the audience laugh.<br /><br />Forgive me, but I have to talk about Chris Farley a little more. I read his biography (\"The Chris Farley Show: A Biography in Three Acts,\" for anyone who cares), and understanding who Chris was in real life made this movie more special to me. Chris Farley was a genuinely good person who struggled, and ultimately failed to conquer his addictions. Although this was the first movie he had a major role in, it is his best film. It really showed who he was, and just how much talent he had. Knowing Chris's story adds another layer to this movie, although it doesn't make it any less funny.<br /><br />Farley and Spade are matched with a good on screen cast. Rob Lowe is suitably slimy as Tommy's \"new brother,\" and Bo Derek is solid as his step-mother. Brian Dennehy is great as Big Tom. Dennehy makes it easy to believe that they're father in son. Big Tom is just as crazy as his son, although he's smarter and more mature. Dan Akroyd gives one of his best performances as Zalinsky, giving Tommy the hard truth behind advertising. Julie Warner is also good as Tommy's love interest, Michelle.<br /><br />For me, Peter Segal is one of the great comedy directors. He keeps the pace quick and energetic, but most importantly, he knows how to make comedy funny. He doesn't belabor the jokes, and he understands that funny actors know what they're doing and he allows them to do it. But Segal goes a step further. He gives \"Tommy Boy\" a friendly, almost nostalgic tone that both tugs the heartstrings (genuinely) and tickles the funnybone.<br /><br />Critics didn't like \"Tommy Boy.\" Shame on them. A movie doesn't have to be super sophisticated or subversively intellectual to be funny (God forbid Farley and Spade were forced to do muted comedy a la \"The Office\"). This is a great movie and one of my all-time favorites.  ...            positive\n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            For once a story of hope highlighted over the tragic reality our youth face. Favela Rising draws one into a scary, unsafe and unfair world and shows through beautiful color and moving music how one man and his dedicated friends choose not to accept that world and change it through action and art. An entertaining, interesting, emotional, aesthetically beautiful film. I showed this film to numerous high school students as well who all live in neighborhoods with poverty and and gun violence and they were enamored with Anderson, the protagonist. I recommend this film to all ages over 13 (due to subtitles and some images of death) from all backgrounds.  ...            positive\n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Okay, I didn't get the Purgatory thing the first time I watched this episode. It seemed like something significant was going on that I couldn't put my finger on. This time those Costa Mesa fires on TV really caught my attention- and it helped that I was just writing an essay on Inferno! But let me see what HASN'T been discussed yet...<br /><br />A TWOP review mentioned that Tony had 7 flights of stairs to go down because of the broken elevator. Yeah, 7 is a significant number for lots of reasons, especially religious, but here's one more for ya. On a hunch I consulted wikipedia, and guess what Dante divided into 7 levels? Purgatorio. Excluding ante-Purgatory and Paradise. (The stuff at the bottom of the stairs and... what Tony can't get to.) <br /><br />On to the allegedly \"random\" monk-slap scene. As soon as the monks appeared, it fit perfectly in place with Tony trying to get out of Purgatory. You can tell he got worried when that Christian commercial (death, disease, and sin) came on, and he's getting more and more desperate because Christian heaven is looking kinda iffy for him. By the time he meets the monks he's thinking \"hey maybe these guys can help me?\" which sounds like contemplating other religions (e.g. Buddhism) and wondering if some other path could take him to \"salvation\". Not that Tony is necessarily literally thinking about becoming a Buddhist, but it appears Finnerty tried that (and messed up). That slap in the face basically tells Tony there's no quick fix- as in, no, you can't suddenly embrace Buddhism and get out of here. <br /><br />Tony was initially not too concerned about getting to heaven. But at the \"conference entrance\", he realizes that's not going to be so easy for him. At first I saw the name vs. driver's license problem as Tony having led sort of a double life, what with the killing people and sleeping around that he kept secret from most people. He feels free to have an affair with quasi-Melfi because \"he's Kevin Finnerty\". He figures out that he CAN fool some people with KF's cards, like hotel receptionists, but it won't get him out of Purgatory. Those helicopters- the helicopters of Heaven?- are keeping track of him and everything he does.<br /><br />After reading all the theories on \"inFinnerty\", though, it seems like KF's identity is a reminder of the infinite different paths Tony could've taken in his life. Possibly along with the car joke involving Infiniti's that made no sense to me otherwise. Aaaand at that point my brain fizzles out.  ...            negative\n",
              "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I was very disappointed with this series. It had lots of cool graphics and that's about it. The level of detail it went into was minimal, and I always got the feeling the audience was being patronized -- there was a lot of what seemed to me as \"This is extremely cool but we're not going to explain it in further detail because you won't get it anyway. Let's just show you some pretty pictures to entertain you.\" The host would drop interesting-sounding words such as \"sparticles\" and \"super-symmetry\" without any attempt at explaining what it was. We had to look it up on Wikipedia.<br /><br />Furthermore, I know quite a bit about superstrings (for a layman) and I found their explanations were convoluted and could have been so much better. They could have chosen MUCH better examples to explain concepts, but instead, the examples they used were confusing and further obscured the subject.<br /><br />Additionally, I got so sick of the repetitiveness. They could easily have condensed the series into one episode if they had cut out all the repetition. They must have shown the clips of the Quantum Caf about 8 times. The host kept saying the same things over and over and over again. I can't remember how many times he said \"The universe is made out of tiny little vibrating strings.\" It's like they were trying to brainwash us into just accepting \"superstrings are the best thing since sliced bread.\"<br /><br />Finally, the show ended off with an unpleasant sense of a \"competition\" between Fermilab and CERN, clearly biased towards Fermilab. This is supposed to be an educational program about quantum physics, not about whether the US is better than Europe or vice versa! I also felt that was part of the patronizing -- \"Audiences need to see some conflict to remain interested.\" Please. Give me a little more credit than that.<br /><br />Overall, 2 thumbs down :-(  ...            negative\n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The first 30 minutes of Tinseltown had my finger teetering on the remote, poised to flick around to watch something else. The premise of two writers, down on their luck, living in a self-storage-space \"bin\" was mildly amusing, but, painfully bland.<br /><br />The introduction of the character, played by Joe Pantoliano - the big deal movie guy, that lives in the park and sleeps in a lavatory, offered hope and I decided to give it a few more minutes. And then a few more until Kristy Swansons introduction as a budding film director & borderline nymphomaniac, added a bit of spice. Her solid acting performance raised her presence above and beyond just a very welcome eye-candy inclusion.<br /><br />Ultimately, the obvious low-budget impacts on the film with poorly shot scenes, stuttured pace and slapstick handling of certain moments. Some of my favourite movies of all time have been low budget, Whithnail & I being one that also deals with 2 guys with a dream, but down on their luck.<br /><br />However, for my money, the actors save Tinseltown from the \"Terrible movie\" archives and just about nudges it into the \"could have been a cult movie\" archives. I laughed out loud at some of the scenes involving Joe Pantoliano's character. In particular, the penultimate scenes in the terribly clichd, but still funny, rich-but-screwed-up characters house, where the story unravels towards it's final moments.<br /><br />I can see how Tinseltown was a great stage play and while the film-makers did their best to translate this to celluloid, it simply didn't work and while I laughed out loud at some of scenes and one liners, I think the first 30 minutes dulled my senses and expectations to such a degree I would have laughed at anything.<br /><br />Unless you're stuck for a novelty coffee coaster, don't pick this up if you see it in a bargain bucket.  ...            negative\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN3nTrhKmNOd"
      },
      "source": [
        "**Second model: Convolutional Neural Network (CNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbdeDcEKmkeZ"
      },
      "source": [
        "Using CNN to conduct sentiment analysis\n",
        "\n",
        "Preparing the data using a different dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv4mHVupa2VX"
      },
      "source": [
        "n = 1234\n",
        "random.seed(n)\n",
        "np.random.seed(n)\n",
        "torch.manual_seed(n)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "# for convolutional layers\n",
        "# batch dimension is first\n",
        "# 'batch_first = true' argument used to tell torchtext to return the permuted data\n",
        "# in CNN, batch dimension is first, so no need to permute data as 'batch_first' is set to true in TEXT field\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm', batch_first = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaTMDsTRroVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21faabec-af26-4838-c266-8a6f8c1f11ea"
      },
      "source": [
        "# splitting the dataset into training and test data\n",
        "train_dataset, test_dataset = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(n))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|| 84.1M/84.1M [00:05<00:00, 15.8MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmTAFjj8rodi"
      },
      "source": [
        "# building the vocabulary and loading the pre-trained word embeddings\n",
        "MAX_VOCAB_SIZE = 25_000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTnQiBHy6bi8",
        "outputId": "be1b1821-e800-48f3-c511-719824e995cd"
      },
      "source": [
        "TEXT.build_vocab(train_dataset, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [04:04, 3.53MB/s]                           \n",
            "100%|| 399916/400000 [00:20<00:00, 18586.52it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeHA3iLorogv"
      },
      "source": [
        "# creating the iterators\n",
        "# batch size of 64 is used\n",
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_dataset, valid_dataset, test_dataset), batch_size = BATCH_SIZE, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpfRIvmzrojh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb18229-9745-44f1-f5d5-995554076f3e"
      },
      "source": [
        "# checking the number of reviews in training, test and validation datasets \n",
        "print(f'Training reviews: {len(train_dataset)}')\n",
        "print(f'Validation reviews: {len(valid_dataset)}')\n",
        "print(f'Testing reviews : {len(test_dataset)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training reviews: 17500\n",
            "Validation reviews: 7500\n",
            "Testing reviews : 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00TROgPFoPJm"
      },
      "source": [
        "Building a CNN for the dataset (Text is 1 dimensional)\n",
        "\n",
        "1.   Convert words into word embeddings to visualize words in 2 dimensions, each word along one axis and other axis for the elements of vectors.\n",
        "2.   Use a filter size of [n*width]. 'n' is the number of sequential words (n-grams, number of tokens in the review) and width is the dimensions of the word or dimensional embeddings (depth of filter).\n",
        "3.   Bi-grams are filters that covers two words at a time, tri-grams covers three words and so on. And each element of the filter has a weight associated with it.\n",
        "4.   The output of this filter is the weighted sum of all elements covered by the filter (single real number). Similarly, the filter moves to cover the next bi-gram and another output is calculated and so on.\n",
        "5.   This is an example of one such filter. CNNs has a plethora of these filters. The main idea is that each filter will learn a different feature to extract. For example, each of the [2*width] filters looks for the occurence of different bi-grams that are relevant for analysing sentiment of movie reviews. And the same goes for different sizes of filters (n-grams) with heights of 3,4,5 etc. \n",
        "6.   Then, use max pooling on the output of the convolutional layers, which takes the maximum value over a dimension. \n",
        "7.   The maximum value is the most important feature for determining the sentiment of the review, which corresponds to the most essential n-gram within the review. Through backpropagation, the weights of the filters are updated so that whenever certain n-grams that are highly indicative of the sentiment are seen, the output of the filter is a high or the highest value amongst all. This high value is then passed through the max pooling layer if it is the maximum value in the output.\n",
        "8.   This model has 100 filters of 3 different sizes (n-grams), i.e., 300 different n-grams. Later, these are concatenated into a single vector and passed through a linear layer to predict the sentiment.\n",
        "9.   Most importantly, input review has to be atleast as long as the largest filter height used. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO8z1q1Cron-"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# implementing the convolutional layers (nn.Conv2d)\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
        "        \n",
        "        # in_channels: number of channels in text/image fed into convolutional layer\n",
        "        # in text, only one single channel\n",
        "        # in_channels: number of filters\n",
        "        # kernel_size: size of filters (n*emb_dim); n is the size of n-grams \n",
        "        # and emb_dim is the dimensional embedding or width of the text\n",
        "        super().__init__()        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)        \n",
        "        self.conv_0 = nn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (filter_sizes[0], embedding_dim))        \n",
        "        self.conv_1 = nn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (filter_sizes[1], embedding_dim))        \n",
        "        self.conv_2 = nn.Conv2d(in_channels = 1, out_channels = n_filters,  kernel_size = (filter_sizes[2], embedding_dim))        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)        \n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        # pass review to an embedding layer to get embeddings    \n",
        "        # second dimension of the input to nn.Conv2d is the channel dimension         \n",
        "        embed_done = self.embedding(text) \n",
        "\n",
        "        # text has no channel dimension, so unsqueeze to make one\n",
        "        # and matches with in_channels (=1) dimension       \n",
        "        embed_done = embed_done.unsqueeze(1)     \n",
        "\n",
        "        # pass tensors through convolutional and pooling layers using ReLU\n",
        "        # (non-linearity) activation function after the conv layers\n",
        "        conv_layer0 = F.relu(self.conv_0(embed_done).squeeze(3))\n",
        "        conv_layer1 = F.relu(self.conv_1(embed_done).squeeze(3))\n",
        "        conv_layer2 = F.relu(self.conv_2(embed_done).squeeze(3))\n",
        "\n",
        "        # pooling layers handles reviews of different lengths\n",
        "        # with max pooling, input to linear layer is the total no. of filters\n",
        "        max_pool0 = F.max_pool1d(conv_layer0, conv_layer0.shape[2]).squeeze(2)\n",
        "        max_pool1 = F.max_pool1d(conv_layer1, conv_layer1.shape[2]).squeeze(2)\n",
        "        max_pool2 = F.max_pool1d(conv_layer2, conv_layer2.shape[2]).squeeze(2)\n",
        "       \n",
        "        # output size of conv layers depends on the input size\n",
        "        # different batches contains reviews of different lengths \n",
        "        # lastly, apply dropout on the concatenated filter outputs \n",
        "        concatenation = self.dropout(torch.cat((max_pool0, max_pool1, max_pool2), dim = 1))\n",
        "\n",
        "        # pass through a linear layer (fully-connected layer) to make predictions\n",
        "        return self.fc(concatenation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y31cjLUXwkQS"
      },
      "source": [
        "The above CNN uses only 3 different sized filters. The below code is a generic CNN that takes in any number of filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QW0V_l9roqZ"
      },
      "source": [
        "# place all conv layers in a nn.ModuleList - function in PyTorch to hold a list\n",
        "# of PyTorch nn.Module\n",
        "\n",
        "# pass arbitrary sized list of filter sizes (generic model) \n",
        "# creates a conv layer for each\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):        \n",
        "        super().__init__()                \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)        \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (fs, embedding_dim)) for fs in filter_sizes])        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # iterate through the list applying each conv layer to get a list of\n",
        "    # conv outputs which is fed into max pooling layer in a list\n",
        "    # comprehension before concatenation and passing through dropout\n",
        "    # and linear layers        \n",
        "    def forward(self, text):\n",
        "        embed_done = self.embedding(text)      \n",
        "        embed_done = embed_done.unsqueeze(1)               \n",
        "        conv_layer_relu = [F.relu(conv(embed_done)).squeeze(3) for conv in self.convs]                \n",
        "        max_pool_drop = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conv_layer_relu]\n",
        "        concatenation = self.dropout(torch.cat(max_pool_drop, dim = 1))\n",
        "        return self.fc(concatenation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDeJoKzpykUK"
      },
      "source": [
        "Creating an instance of our CNN model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcaLSGy9rx2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094956f7-459b-46b8-fc6c-4098cd8deee7"
      },
      "source": [
        "dimension_input = len(TEXT.vocab)\n",
        "# dimensional embeddings\n",
        "dimn_embedding = 100\n",
        "# number of filters\n",
        "number_filters = 100\n",
        "# size of the filters\n",
        "size_filter = [3,4,5]\n",
        "# output size\n",
        "dimension_output = 1\n",
        "# dropout (value of 'p')\n",
        "p = 0.5\n",
        "# padding\n",
        "padding = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "# applying all these to the CNN\n",
        "model = CNN(dimension_input, dimn_embedding, number_filters, size_filter, dimension_output, p, padding)\n",
        "\n",
        "# check number of parameters in CNN model\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,620,801 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM7f8g6uzAt5"
      },
      "source": [
        "Loading the pre-trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UqUboiKryAI"
      },
      "source": [
        "embed_pretrain = TEXT.vocab.vectors\n",
        "# weights\n",
        "model.embedding.weight.data.copy_(embed_pretrain)\n",
        "\n",
        "# zero the initial weights of the unknown and padding tokens\n",
        "token = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "model.embedding.weight.data[token] = torch.zeros(dimn_embedding)\n",
        "model.embedding.weight.data[padding] = torch.zeros(dimn_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyC9HDFOzN4M"
      },
      "source": [
        "Next, now it is ready to train our model. The optimizer and loss function (criterion) are initialized. Here, I have used the ADAM optimizer and Binary Cross Entropy with Logits Loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V66eaXlnr072"
      },
      "source": [
        "# importing ADAM optimizer\n",
        "import torch.optim as optim\n",
        "# set ADAM optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "# set the loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# set model and criterion on GPU\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnH5VyBCz5Sl"
      },
      "source": [
        "Implementing a function to calculate accuracy in order to check the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcdKyXiir0-I"
      },
      "source": [
        "# returns accuracy per batch, will return, for example, 0.8 instead of 8.\n",
        "def binary_accuracy(preds, y):\n",
        "  # rounds predictions to the closest integer\n",
        "    predictions_rounded = torch.round(torch.sigmoid(preds))\n",
        "    true_prediction = (predictions_rounded == y).float() # float better for division purposes\n",
        "    accuracy = true_prediction.sum() / len(true_prediction)\n",
        "    return accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yb90IZur1Al"
      },
      "source": [
        "# function for training the model\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    # initialise the epoch loss and accuracy\n",
        "    epoch_accuracy = 0 \n",
        "    epoch_loss = 0\n",
        "    model.train() # to ensure dropout is turned ON while training\n",
        "    \n",
        "    for batch in iterator:        \n",
        "        optimizer.zero_grad()        \n",
        "        predictions = model(batch.text).squeeze(1)        \n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        accuracy  = binary_accuracy(predictions, batch.label)        \n",
        "        loss.backward()        \n",
        "        optimizer.step()        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_accuracy  += accuracy .item()        \n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRBhtJ-fr4PD"
      },
      "source": [
        "# function for testing the model\n",
        "def evaluate(model, iterator, criterion):\n",
        "    # initialise the epoch loss and accuracy\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0    \n",
        "    model.eval() # to ensure dropout is turned OFF while evaluating/testing\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)            \n",
        "            loss = criterion(predictions, batch.label)            \n",
        "            accuracy = binary_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_accuracy += accuracy.item()        \n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIz34dKIr4RU"
      },
      "source": [
        "# importing time library to define function to tell the time taken of our\n",
        "# epochs \n",
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    time_taken = end_time - start_time\n",
        "    time_taken_mins = int(time_taken / 60)\n",
        "    time_taken_secs = int(time_taken - (time_taken_mins * 60))\n",
        "    return time_taken_mins, time_taken_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjCzQTY81CLl"
      },
      "source": [
        "**Training the CNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zfrhI7Pr4Tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513f3308-b609-4271-e0d8-cee7d6980241"
      },
      "source": [
        "# 5 epochs are enough to view the values of loss and accuracy\n",
        "number_epochs = 5\n",
        "good_validationloss = float('inf') # set to float\n",
        "for epoch in range(number_epochs):\n",
        "    start_time = time.time()    \n",
        "    # calculating the training loss and accuracy and the validation loss\n",
        "    # and accuracy\n",
        "    train_loss, train_accuracy = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_accuracy = evaluate(model, valid_iterator, criterion)    \n",
        "    end_time = time.time()\n",
        "    epoch_minutes, epoch_secs = epoch_time(start_time, end_time)    \n",
        "    if valid_loss < good_validationloss:\n",
        "        good_validationloss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    # print the training loss and accuracy and validation loss and accuracy\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_minutes}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_accuracy*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_accuracy*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.427 | Train Acc: 80.43%\n",
            "\t Val. Loss: 0.366 |  Val. Acc: 83.63%\n",
            "Epoch: 02 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.297 | Train Acc: 87.73%\n",
            "\t Val. Loss: 0.327 |  Val. Acc: 86.32%\n",
            "Epoch: 03 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.218 | Train Acc: 91.40%\n",
            "\t Val. Loss: 0.339 |  Val. Acc: 86.17%\n",
            "Epoch: 04 | Epoch Time: 0m 30s\n",
            "\tTrain Loss: 0.150 | Train Acc: 94.47%\n",
            "\t Val. Loss: 0.324 |  Val. Acc: 87.12%\n",
            "Epoch: 05 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.105 | Train Acc: 96.52%\n",
            "\t Val. Loss: 0.348 |  Val. Acc: 86.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOpdJ20Z1YT8"
      },
      "source": [
        "This function will prompt the user to input their reviews. Based on the review, the model will the predict whether the sentiment of the review is positive or negative along with how accurate the model predicts the sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86nhuB-Nr4YR"
      },
      "source": [
        "import spacy\n",
        "prompt = spacy.load('en_core_web_sm')\n",
        "\n",
        "# minimum_length is set to 10000 so that utmost 10000 tokens are accepted for computing\n",
        "# the outcome, i.e., 10000 words in a review which is more than enough\n",
        "def classify_predict_sentiment(model, sentence, minimum_length = 10000):\n",
        "    model.eval()\n",
        "    tokenization_done = [tok.text for tok in prompt.tokenizer(sentence)]\n",
        "    # classify_predict_sentiment function accepts minimum length argument also by changing\n",
        "    # minimum_length\n",
        "    # If tokenization_done input sentence is less than minimum_length tokens, then we append\n",
        "    # padding tokens ('<pad>') to make it minimum_length tokens\n",
        "    if len(tokenization_done) < minimum_length:\n",
        "        tokenization_done += ['<pad>'] * (minimum_length - len(tokenization_done))\n",
        "    indexing = [TEXT.vocab.stoi[t] for t in tokenization_done]\n",
        "    box = torch.LongTensor(indexing).to(device)\n",
        "    box = box.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(box))\n",
        "    \n",
        "    # if the accuracy of the review is less than 0.5, it shall be considered\n",
        "    # a negative review and anything above 0.5 shall be considered a positive\n",
        "    # review\n",
        "    if prediction.item() < 0.5:\n",
        "      print(f'Negative Review')\n",
        "    else:\n",
        "      print(f'Positive Review')\n",
        "\n",
        "    return print(f'Accuracy of this review: {prediction.item():.8f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0NQwfPM29hC"
      },
      "source": [
        "The following positive and negative reviews are fed into the model and the outcome is displayed along with the accuracy from the model, i.e., how accurate the model predicts whether it is a positive or negative review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaFi2XAer4a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ab14aa-8390-4a5a-c985-8802e03f647f"
      },
      "source": [
        "classify_predict_sentiment(model, \"I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her sexy image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than Devil Wears Prada and more interesting than Superman a great comedy to go see with friends.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Review\n",
            "Accuracy of this review: 0.91910881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7FX8Xr3sA5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3086d245-5817-4a37-ef62-46d6bc95df43"
      },
      "source": [
        "classify_predict_sentiment(model, \"This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative Review\n",
            "Accuracy of this review: 0.00040174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmYHLkkltOW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc0ca11-af61-4ee1-d847-b109535b468e"
      },
      "source": [
        "classify_predict_sentiment(model, \"This a fantastic movie of three prisoners who become famous. One of the actors is george clooney and I'm not a fan but this roll is not bad. Another good thing about the movie is the soundtrack (The man of constant sorrow). I recommand this movie to everybody. Greetings Bart\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Review\n",
            "Accuracy of this review: 0.97659189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJnOySA_HBAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57fe80e-04dd-4f5b-e10b-fbb142daf66a"
      },
      "source": [
        "classify_predict_sentiment(model,\"I saw this movie when I was about 12 when it came out. I recall the scariest scene was the big bird eating men dangling helplessly from parachutes right out of the air. The horror. The horror.<br /><br />As a young kid going to these cheesy B films on Saturday afternoons, I still was tired of the formula for these monster type movies that usually included the hero, a beautiful woman who might be the daughter of a professor and a happy resolution when the monster died in the end. I didn't care much for the romantic angle as a 12 year old and the predictable plots. I love them now for the unintentional humor.<br /><br />But, about a year or so later, I saw Psycho when it came out and I loved that the star, Janet Leigh, was bumped off early in the film. I sat up and took notice at that point. Since screenwriters are making up the story, make it up to be as scary as possible and not from a well-worn formula. There are no rules.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative Review\n",
            "Accuracy of this review: 0.03677244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMEaOdhzHLtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a4fd08-91a1-4240-9ae0-86ed99419081"
      },
      "source": [
        "classify_predict_sentiment(model,\"The Karen Carpenter Story shows a little more about singer Karen Carpenter's complex life. Though it fails in giving accurate facts, and details.<br /><br />Cynthia Gibb (portrays Karen) was not a fine election. She is a good actress , but plays a very naive and sort of dumb Karen Carpenter. I think that the role needed a stronger character. Someone with a stronger personality.<br /><br />Louise Fletcher role as Agnes Carpenter is terrific, she does a great job as Karen's mother.<br /><br />It has great songs, which could have been included in a soundtrack album. Unfortunately they weren't, though this movie was on the top of the ratings in USA and other several countries.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Review\n",
            "Accuracy of this review: 0.98216945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiZK-bCGHxtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca08afc-2921-4a51-c0d5-b1cb6032517e"
      },
      "source": [
        "classify_predict_sentiment(model,\"I watched this film not really expecting much, I got it in a pack of 5 films, all of which were pretty terrible in their own way for under a fiver so what could I expect? and you know what I was right, they were all terrible, this movie has a few (and a few is stretching it) interesting points, the occasional camcorder view is a nice touch, the drummer is very like a drummer, i.e damned annoying and, well thats about it actually, the problem is that its just so boring, in what I can only assume was an attempt to build tension, a whole lot of nothing happens and when it does its utterly tedious (I had my thumb on the fast forward button, ready to press for most of the movie, but gave it a go) and seriously is the lead singer of the band that great looking, coz they don't half mention how beautiful he is a hell of a lot, I thought he looked a bit like a meercat, all this and I haven't even mentioned the killer, I'm not even gonna go into it, its just not worth explaining. Anyway as far as I'm concerned Star and London are just about the only reason to watch this and with the exception of London (who was actually quite funny) it wasn't because of their acting talent, I've certainly seen a lot worse, but I've also seen a lot better. Best avoid unless your bored of watching paint dry.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative Review\n",
            "Accuracy of this review: 0.00015149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6ev05zKIbxf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}